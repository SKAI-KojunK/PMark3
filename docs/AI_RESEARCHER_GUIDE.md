# AI ì—°êµ¬ì›ì„ ìœ„í•œ PMark3 ê°œë°œ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

ì´ ë¬¸ì„œëŠ” AI ì—°êµ¬ì›(í”„ë¡œì íŠ¸íŒ€)ì´ PMark3 í”„ë¡œí† íƒ€ì…ì„ ì´í•´í•˜ê³  ê°œì„ í•˜ê¸° ìœ„í•œ ìƒì„¸ ê°€ì´ë“œì…ë‹ˆë‹¤. ì „ë¬¸ ê°œë°œìê°€ ì•„ë‹Œ ì—°êµ¬ì›ì„ ìœ„í•´ ê° í•¨ìˆ˜, í´ë˜ìŠ¤, íŒŒì¼ì˜ ì—°ê³„ ì§€ì ê³¼ ê¸°ëŠ¥ì„ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ—‚ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡° ì´í•´

### ì „ì²´ íŒŒì¼ êµ¬ì¡°
```
PMark3/
â”œâ”€â”€ backend/app/
â”‚   â”œâ”€â”€ agents/parser.py           # ğŸ¯ ì‚¬ìš©ì ì…ë ¥ íŒŒì‹±
â”‚   â”œâ”€â”€ logic/
â”‚   â”‚   â”œâ”€â”€ normalizer.py          # ğŸ”§ ìš©ì–´ ì •ê·œí™”
â”‚   â”‚   â””â”€â”€ recommender.py         # ğŸ’¡ ì¶”ì²œ ì—”ì§„
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ chat.py               # ğŸŒ ì±„íŒ… API
â”‚   â”‚   â””â”€â”€ work_details.py       # ğŸ“ ì‘ì—… ìƒì„¸ API
â”‚   â”œâ”€â”€ database.py               # ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬
â”‚   â”œâ”€â”€ session_manager.py        # ğŸ‘¤ ì„¸ì…˜ ê´€ë¦¬
â”‚   â”œâ”€â”€ models.py                 # ğŸ“Š ë°ì´í„° ëª¨ë¸
â”‚   â””â”€â”€ config.py                 # âš™ï¸ ì„¤ì •
â”œâ”€â”€ notebooks/                     # ğŸ§ª ì‹¤í—˜ìš© ë…¸íŠ¸ë¶
â”œâ”€â”€ docs/                         # ğŸ“š ë¬¸ì„œ
â””â”€â”€ data/                         # ğŸ’¾ ë°ì´í„° íŒŒì¼
```

### í•µì‹¬ ë°ì´í„° íë¦„
```mermaid
graph LR
    A[ì‚¬ìš©ì ì…ë ¥] --> B[parser.py<br/>íŒŒì‹±]
    B --> C[normalizer.py<br/>ì •ê·œí™”]
    C --> D[database.py<br/>ê²€ìƒ‰]
    D --> E[recommender.py<br/>ì¶”ì²œ]
    E --> F[ì‘ë‹µ ìƒì„±]
    
    G[session_manager.py<br/>ì„¸ì…˜ ê´€ë¦¬] -.-> B
    G -.-> C
    G -.-> E
```

## ğŸ¯ í•µì‹¬ ëª¨ë“ˆ ìƒì„¸ ê°€ì´ë“œ

### 1. parser.py - ì‚¬ìš©ì ì…ë ¥ íŒŒì‹±ê¸°

#### ğŸ” ì—­í• ê³¼ ëª©ì 
- **ì£¼ ê¸°ëŠ¥**: ìì—°ì–´ ì‚¬ìš©ì ì…ë ¥ì„ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜
- **ì²˜ë¦¬ ì‹œë‚˜ë¦¬ì˜¤**:
  - S1: ìì—°ì–´ ì…ë ¥ ("No.1 PE ì••ë ¥ë² ì ¤ ê³ ì¥")
  - S2: ITEMNO ì…ë ¥ ("44043-CA1-6"-P")
  - S3: ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì…ë ¥

#### ğŸ”§ ì£¼ìš” í•¨ìˆ˜ë“¤

```python
class InputParser:
    def parse_input_with_context(self, user_input: str, conversation_history: list, session_id: str):
        """
        ğŸ¯ ë©”ì¸ íŒŒì‹± í•¨ìˆ˜
        
        ì…ë ¥ë°›ëŠ” ê²ƒ:
        - user_input: ì‚¬ìš©ìê°€ ì…ë ¥í•œ í…ìŠ¤íŠ¸
        - conversation_history: ì´ì „ ëŒ€í™” ë‚´ìš©
        - session_id: ì„¸ì…˜ ì‹ë³„ì
        
        ë°˜í™˜í•˜ëŠ” ê²ƒ:
        - ParsedInput ê°ì²´ (location, equipment_type, status_code, priority í¬í•¨)
        
        AI ì—°êµ¬ì› ì‹¤í—˜ í¬ì¸íŠ¸:
        1. LLM ëª¨ë¸ êµì²´ (GPT-4 â†’ Mistral, Qwen)
        2. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê°œì„ 
        3. ì‹œë‚˜ë¦¬ì˜¤ ë¶„ê¸° ë¡œì§ ìµœì í™”
        """
    
    def _create_scenario_1_prompt(self, user_input: str):
        """
        ğŸ¨ ì‹œë‚˜ë¦¬ì˜¤ 1ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
        
        ì‹¤í—˜ ê°€ëŠ¥í•œ ì˜ì—­:
        - í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìµœì í™”
        - ì˜ˆì‹œ ì¶”ê°€/ìˆ˜ì •
        - ì¶”ì¶œ ê·œì¹™ ê°œì„ 
        """
```

#### ğŸ§ª ì‹¤í—˜ ë°©ë²•
```python
# notebooks/01_parser_experiment.ipynbì—ì„œ ì‹¤í—˜
# 1. ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸
# 2. LLM ëª¨ë¸ ë¹„êµ
# 3. ì •í™•ë„ ì¸¡ì •

# ì‹¤í—˜ ì˜ˆì‹œ
parser = InputParser()
test_inputs = [
    "No.1 PE ì••ë ¥ë² ì ¤ ê³ ì¥",
    "ì„ìœ ì œí’ˆë°°í•©/ì €ì¥ Motor Operated Valve ì‘ë™ë¶ˆëŸ‰",
    "44043-CA1-6\"-P Leak ë³¼íŒ… ì‘ì—…"
]

for input_text in test_inputs:
    result = parser.parse_input_with_context(input_text, [], "test_session")
    print(f"ì…ë ¥: {input_text}")
    print(f"ê²°ê³¼: {result}")
    print(f"ì‹ ë¢°ë„: {result.confidence}")
```

### 2. normalizer.py - ìš©ì–´ ì •ê·œí™”ê¸°

#### ğŸ” ì—­í• ê³¼ ëª©ì 
- **ì£¼ ê¸°ëŠ¥**: íŒŒì‹±ëœ ìš©ì–´ë¥¼ í‘œì¤€ ìš©ì–´ë¡œ ë³€í™˜
- **í˜„ì¬ ë°©ì‹**: LLM ê¸°ë°˜ ì •ê·œí™”
- **ê°œì„  ë°©í–¥**: ë²¡í„° ì„ë² ë”© ê¸°ë°˜ ì •ê·œí™”

#### ğŸ”§ ì£¼ìš” í•¨ìˆ˜ë“¤

```python
class LLMNormalizer:
    def normalize_term(self, term: str, category: str) -> Tuple[str, float]:
        """
        ğŸ”§ ìš©ì–´ ì •ê·œí™” í•¨ìˆ˜
        
        ì…ë ¥ë°›ëŠ” ê²ƒ:
        - term: ì •ê·œí™”í•  ìš©ì–´ ("ì••ë ¥ë² ì ¤")
        - category: ì¹´í…Œê³ ë¦¬ ("equipment", "location", "status", "priority")
        
        ë°˜í™˜í•˜ëŠ” ê²ƒ:
        - (ì •ê·œí™”ëœ ìš©ì–´, ì‹ ë¢°ë„ ì ìˆ˜)
        
        í˜„ì¬ì˜ í•œê³„ì :
        1. LLM í˜¸ì¶œë¡œ ì¸í•œ ì§€ì—° ì‹œê°„
        2. ì¼ê´€ì„± ë¶€ì¡± (ê°™ì€ ì…ë ¥ì— ë‹¤ë¥¸ ê²°ê³¼)
        3. ë¹„ìš© ë¬¸ì œ
        
        AI ì—°êµ¬ì› ê°œì„  ê¸°íšŒ:
        1. ë²¡í„° ì„ë² ë”© ê¸°ë°˜ ì •ê·œí™” êµ¬í˜„
        2. ìºì‹± ì‹œìŠ¤í…œ ë„ì…
        3. í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²• (ë£° ê¸°ë°˜ + ë²¡í„°)
        """
    
    def _get_db_terms(self, category: str) -> list:
        """
        ğŸ“š DBì—ì„œ í‘œì¤€ ìš©ì–´ ì¶”ì¶œ
        
        ê°œì„  í¬ì¸íŠ¸:
        - ìš©ì–´ ë¹ˆë„ ê¸°ë°˜ ìš°ì„ ìˆœìœ„
        - ë™ì  ìš©ì–´ ì—…ë°ì´íŠ¸
        - ë‹¤êµ­ì–´ ì§€ì›
        """
```

#### ğŸ§ª ì‹¤í—˜ ë°©ë²•
```python
# notebooks/02_normalizer_experiment.ipynbì—ì„œ ì‹¤í—˜

# í˜„ì¬ ë°©ì‹ vs ë²¡í„° ê¸°ë°˜ ë¹„êµ
from sentence_transformers import SentenceTransformer

# 1. í˜„ì¬ LLM ë°©ì‹ í…ŒìŠ¤íŠ¸
normalizer = LLMNormalizer()
result1 = normalizer.normalize_term("ì••ë ¥ë² ì ¤", "equipment")

# 2. ë²¡í„° ê¸°ë°˜ ì‹¤í—˜
model = SentenceTransformer('jhgan/ko-sbert-multitask')
# ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ ì •ê·œí™” ì‹¤í—˜
```

### 3. recommender.py - ì¶”ì²œ ì—”ì§„

#### ğŸ” ì—­í• ê³¼ ëª©ì 
- **ì£¼ ê¸°ëŠ¥**: íŒŒì‹±ëœ ì…ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ìœ ì‚¬í•œ ì‘ì—… ì¶”ì²œ
- **í˜„ì¬ ë°©ì‹**: ë¬¸ìì—´ ìœ ì‚¬ë„ + ê°€ì¤‘ì¹˜ ê³„ì‚°
- **ê°œì„  ë°©í–¥**: ë²¡í„° ê²€ìƒ‰ + í˜‘ì—… í•„í„°ë§

#### ğŸ”§ ì£¼ìš” í•¨ìˆ˜ë“¤

```python
class RecommendationEngine:
    def get_recommendations(self, parsed_input: ParsedInput, limit: int = 5):
        """
        ğŸ’¡ ì¶”ì²œ ìƒì„± í•¨ìˆ˜
        
        ì²˜ë¦¬ ê³¼ì •:
        1. database.pyë¥¼ í†µí•´ ìœ ì‚¬í•œ ì‘ì—… ê²€ìƒ‰
        2. ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°
        3. ìš°ì„ ìˆœìœ„ ì •ë ¬
        4. ìƒìœ„ Nê°œ ë°˜í™˜
        
        AI ì—°êµ¬ì› ê°œì„  ê¸°íšŒ:
        1. ë²¡í„° ê²€ìƒ‰ ë„ì…
        2. í˜‘ì—… í•„í„°ë§ ì ìš©
        3. ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ì²œ
        4. ì‚¬ìš©ì í”¼ë“œë°± í•™ìŠµ
        """
    
    def _calculate_simple_similarity_score(self, parsed_input, notification):
        """
        ğŸ“Š ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°
        
        í˜„ì¬ ê°€ì¤‘ì¹˜:
        - ì„¤ë¹„ìœ í˜•: 35%
        - ìœ„ì¹˜: 35%
        - í˜„ìƒì½”ë“œ: 20%
        - ìš°ì„ ìˆœìœ„: 10%
        
        ì‹¤í—˜ í¬ì¸íŠ¸:
        1. ê°€ì¤‘ì¹˜ ìµœì í™”
        2. ìƒˆë¡œìš´ ìœ ì‚¬ë„ ë©”íŠ¸ë¦­ ë„ì…
        3. ìƒí™©ë³„ ë™ì  ê°€ì¤‘ì¹˜
        """
```

#### ğŸ§ª ì‹¤í—˜ ë°©ë²•
```python
# notebooks/03_recommender_experiment.ipynbì—ì„œ ì‹¤í—˜

# 1. ê°€ì¤‘ì¹˜ ì¡°ì • ì‹¤í—˜
weights_experiments = [
    {"location": 0.4, "equipment": 0.3, "status": 0.2, "priority": 0.1},
    {"location": 0.3, "equipment": 0.4, "status": 0.2, "priority": 0.1},
    {"location": 0.35, "equipment": 0.35, "status": 0.25, "priority": 0.05}
]

# 2. ë²¡í„° ê¸°ë°˜ ì¶”ì²œ ì‹¤í—˜
# 3. í˜‘ì—… í•„í„°ë§ ì‹¤í—˜
```

### 4. database.py - ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ì

#### ğŸ” ì—­í• ê³¼ ëª©ì 
- **ì£¼ ê¸°ëŠ¥**: ë°ì´í„° ê²€ìƒ‰ ë° ê´€ë¦¬
- **í˜„ì¬**: SQLite ì‚¬ìš©
- **Production**: Azure SQL Database ì—°ë™ ì˜ˆì •

#### ğŸ”§ ì£¼ìš” í•¨ìˆ˜ë“¤

```python
class DatabaseManager:
    def search_similar_notifications(self, equip_type=None, location=None, 
                                   status_code=None, priority=None, limit=15):
        """
        ğŸ” ìœ ì‚¬í•œ ì‘ì—… ê²€ìƒ‰
        
        ê²€ìƒ‰ ì „ëµ:
        1. ìœ„ì¹˜ ê¸°ë°˜ ìš°ì„  ê²€ìƒ‰
        2. ì„¤ë¹„ìœ í˜• ë§¤ì¹­
        3. í˜„ìƒì½”ë“œ ë§¤ì¹­
        4. ìš°ì„ ìˆœìœ„ ê³ ë ¤
        
        AI ì—°êµ¬ì› ì‹¤í—˜ í¬ì¸íŠ¸:
        1. ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ ê°œì„ 
        2. ì¸ë±ì‹± ìµœì í™”
        3. ë²¡í„° ê²€ìƒ‰ í†µí•©
        """
    
    def search_by_itemno(self, itemno: str, limit: int = 15):
        """
        ğŸ¯ ITEMNO ê¸°ë°˜ ê²€ìƒ‰
        
        ê²€ìƒ‰ ë‹¨ê³„:
        1. ì •í™•í•œ ë§¤ì¹­
        2. ë¶€ë¶„ ë§¤ì¹­
        3. íŒ¨í„´ ìœ ì‚¬ì„± ê²€ìƒ‰
        
        ê°œì„  ê¸°íšŒ:
        - í¼ì§€ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜
        - ì •ê·œí‘œí˜„ì‹ ìµœì í™”
        """
```

### 5. session_manager.py - ì„¸ì…˜ ê´€ë¦¬ì

#### ğŸ” ì—­í• ê³¼ ëª©ì 
- **ì£¼ ê¸°ëŠ¥**: ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ ë° ê´€ë¦¬
- **í˜„ì¬**: ë©”ëª¨ë¦¬ ê¸°ë°˜ ì„¸ì…˜
- **Production**: Redis/Azure Cache í™œìš© ì˜ˆì •

#### ğŸ”§ ì£¼ìš” í•¨ìˆ˜ë“¤

```python
class SessionManager:
    def create_session(self) -> str:
        """
        ğŸ‘¤ ìƒˆ ì„¸ì…˜ ìƒì„±
        
        í¬í•¨ ì •ë³´:
        - ì„¸ì…˜ ID
        - ìƒì„± ì‹œê°„
        - ëŒ€í™” íˆìŠ¤í† ë¦¬
        - ì»¨í…ìŠ¤íŠ¸ ìš”ì•½
        """
    
    def update_session(self, session_id: str, message: str, context: dict):
        """
        ğŸ”„ ì„¸ì…˜ ì •ë³´ ì—…ë°ì´íŠ¸
        
        ê´€ë¦¬ ìš”ì†Œ:
        - ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬
        - ì»¨í…ìŠ¤íŠ¸ ëˆ„ì 
        - ì„¸ì…˜ ë§Œë£Œ ê´€ë¦¬
        """
```

## ğŸ§ª ì‹¤í—˜ í™˜ê²½ êµ¬ì„±

### ì‹¤í—˜ìš© ë°ì´í„° ì¤€ë¹„

```python
# ì‹¤í—˜ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„±
sample_inputs = [
    {
        "input": "No.1 PE ì••ë ¥ë² ì ¤ ê³ ì¥",
        "expected": {
            "location": "No.1 PE",
            "equipment_type": "Pressure Vessel",
            "status_code": "ê³ ì¥",
            "priority": None
        }
    },
    {
        "input": "ì„ìœ ì œí’ˆë°°í•©/ì €ì¥ Motor Operated Valve ì‘ë™ë¶ˆëŸ‰. ê¸´ê¸‰ì‘ì—… ìš”ë§",
        "expected": {
            "location": "ì„ìœ ì œí’ˆë°°í•©/ì €ì¥",
            "equipment_type": "Motor Operated Valve",
            "status_code": "ì‘ë™ë¶ˆëŸ‰",
            "priority": "ê¸´ê¸‰ì‘ì—…"
        }
    }
]

# Ground Truth ë°ì´í„°ì…‹ êµ¬ì„±
ground_truth = {
    "parsing_accuracy": sample_inputs,
    "normalization_pairs": [
        ("ì••ë ¥ë² ì ¤", "[VEDR]Pressure Vessel/ Drum"),
        ("ëª¨í„°ë°¸ë¸Œ", "[MVVV]Motor Operated Valve/ Motor Operated Valve")
    ],
    "recommendation_relevance": [
        # ì¿¼ë¦¬ì™€ ê´€ë ¨ ìˆëŠ” ì‘ì—… ID ë§¤í•‘
    ]
}
```

### ì„±ëŠ¥ ì¸¡ì • ë„êµ¬

```python
class ExperimentTracker:
    """
    ì‹¤í—˜ ê²°ê³¼ ì¶”ì  ë° ë¶„ì„
    
    ì‚¬ìš©ë²•:
    1. tracker = ExperimentTracker("parsing_experiment")
    2. tracker.log_result(model="gpt-4", accuracy=0.95, speed=1.2)
    3. tracker.compare_models()
    """
    
    def __init__(self, experiment_name: str):
        self.experiment_name = experiment_name
        self.results = []
    
    def log_result(self, **metrics):
        """ì‹¤í—˜ ê²°ê³¼ ê¸°ë¡"""
        result = {
            "timestamp": datetime.now(),
            "metrics": metrics
        }
        self.results.append(result)
    
    def compare_models(self) -> pd.DataFrame:
        """ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ"""
        df = pd.DataFrame([r["metrics"] for r in self.results])
        return df.describe()
    
    def plot_performance(self, metric_name: str):
        """ì„±ëŠ¥ ì‹œê°í™”"""
        import matplotlib.pyplot as plt
        
        values = [r["metrics"].get(metric_name, 0) for r in self.results]
        plt.plot(values)
        plt.title(f"{metric_name} Performance")
        plt.ylabel(metric_name)
        plt.xlabel("Experiment")
        plt.show()
```

## ğŸ”¬ ì‹¤í—˜ ê°€ì´ë“œë¼ì¸

### 1. íŒŒì‹± ë¡œì§ ì‹¤í—˜

```python
# ëª©í‘œ: íŒŒì‹± ì •í™•ë„ í–¥ìƒ
# ë°©ë²•: í”„ë¡¬í”„íŠ¸ ìµœì í™”, ëª¨ë¸ êµì²´

# ì‹¤í—˜ 1: í”„ë¡¬í”„íŠ¸ ìµœì í™”
prompts = [
    "ê¸°ì¡´ í”„ë¡¬í”„íŠ¸",
    "ì˜ˆì‹œê°€ ì¶”ê°€ëœ í”„ë¡¬í”„íŠ¸", 
    "ë‹¨ê³„ë³„ ì¶”ì¶œ í”„ë¡¬í”„íŠ¸"
]

for prompt in prompts:
    accuracy = test_parsing_with_prompt(prompt)
    tracker.log_result(prompt_type=prompt, accuracy=accuracy)

# ì‹¤í—˜ 2: LLM ëª¨ë¸ ë¹„êµ
models = ["gpt-4", "gpt-3.5-turbo", "mistral-7b", "qwen3-14b"]

for model in models:
    parser = InputParser(model=model)
    accuracy, speed = evaluate_parser(parser)
    tracker.log_result(model=model, accuracy=accuracy, speed=speed)
```

### 2. ì •ê·œí™” ì‹¤í—˜

```python
# ëª©í‘œ: ì •ê·œí™” ì¼ê´€ì„± ë° ì†ë„ í–¥ìƒ
# ë°©ë²•: ë²¡í„° ê¸°ë°˜ ì •ê·œí™” ë„ì…

# ì‹¤í—˜ 1: LLM vs ë²¡í„° ì„ë² ë”©
from sentence_transformers import SentenceTransformer

# LLM ë°©ì‹
llm_normalizer = LLMNormalizer()
llm_accuracy = evaluate_normalization(llm_normalizer)

# ë²¡í„° ë°©ì‹
vector_model = SentenceTransformer('jhgan/ko-sbert-multitask')
vector_normalizer = VectorNormalizer(vector_model)
vector_accuracy = evaluate_normalization(vector_normalizer)

# ê²°ê³¼ ë¹„êµ
tracker.log_result(method="llm", accuracy=llm_accuracy)
tracker.log_result(method="vector", accuracy=vector_accuracy)
```

### 3. ì¶”ì²œ ì‹œìŠ¤í…œ ì‹¤í—˜

```python
# ëª©í‘œ: ì¶”ì²œ ì •í™•ë„ ë° ë‹¤ì–‘ì„± í–¥ìƒ
# ë°©ë²•: ë²¡í„° ê²€ìƒ‰, í˜‘ì—… í•„í„°ë§ ë„ì…

# ì‹¤í—˜ 1: ìœ ì‚¬ë„ ë©”íŠ¸ë¦­ ë¹„êµ
similarity_functions = [
    "levenshtein",
    "cosine_similarity", 
    "jaccard",
    "semantic_similarity"
]

for sim_func in similarity_functions:
    recommender = RecommendationEngine(similarity=sim_func)
    precision, recall = evaluate_recommendations(recommender)
    tracker.log_result(similarity=sim_func, precision=precision, recall=recall)
```

## ğŸ¯ ì‹¤í—˜ ìš°ì„ ìˆœìœ„

### ë†’ì€ ìš°ì„ ìˆœìœ„ (ì¦‰ì‹œ ì‹¤í—˜ ê°€ëŠ¥)
1. **íŒŒì‹± í”„ë¡¬í”„íŠ¸ ìµœì í™”**: í˜„ì¬ ì½”ë“œ ìˆ˜ì • ì—†ì´ í”„ë¡¬í”„íŠ¸ë§Œ ë³€ê²½
2. **ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜ ì¡°ì •**: recommender.pyì˜ ê°€ì¤‘ì¹˜ ì‹¤í—˜
3. **ì •ê·œí™” ì„ê³„ê°’ ì¡°ì •**: ì‹ ë¢°ë„ ì„ê³„ê°’ ìµœì í™”

### ì¤‘ê°„ ìš°ì„ ìˆœìœ„ (ë²¡í„° ì‹œìŠ¤í…œ êµ¬ì¶• í›„)
1. **ë²¡í„° ê¸°ë°˜ ì •ê·œí™”**: SentenceTransformer í™œìš©
2. **ë²¡í„° ê²€ìƒ‰ ì‹œìŠ¤í…œ**: FAISS, Chroma ë“± ë„ì…
3. **í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ**: ê¸°ì¡´ + ë²¡í„° ê²€ìƒ‰ ê²°í•©

### ë‚®ì€ ìš°ì„ ìˆœìœ„ (Production ì „í™˜ ì‹œ)
1. **ë¡œì»¬ LLM í†µí•©**: vLLM ê¸°ë°˜ ì„œë¹™
2. **ì‹¤ì‹œê°„ í•™ìŠµ ì‹œìŠ¤í…œ**: ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜
3. **ë©€í‹°ëª¨ë‹¬ ì§€ì›**: ì´ë¯¸ì§€, ìŒì„± ì…ë ¥ ì²˜ë¦¬

## ğŸ’¡ ì‹¤í—˜ ì‹œ ì£¼ì˜ì‚¬í•­

### 1. ì¬í˜„ì„± í™•ë³´
```python
# ì‹¤í—˜ í™˜ê²½ ê³ ì •
import random
import numpy as np

def set_random_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    # torch.manual_seed(seed) if using PyTorch

# ëª¨ë“  ì‹¤í—˜ ì‹œì‘ ì‹œ í˜¸ì¶œ
set_random_seed(42)
```

### 2. ì„±ëŠ¥ ì¸¡ì • ì¼ê´€ì„±
```python
# ì„±ëŠ¥ ì¸¡ì • í‘œì¤€í™”
def measure_performance(func, *args, **kwargs):
    start_time = time.time()
    result = func(*args, **kwargs)
    end_time = time.time()
    
    return {
        "result": result,
        "execution_time": end_time - start_time,
        "memory_usage": get_memory_usage()
    }
```

### 3. ì‹¤í—˜ ê²°ê³¼ ë¬¸ì„œí™”
```python
# ì‹¤í—˜ ë³´ê³ ì„œ ìë™ ìƒì„±
def generate_experiment_report(tracker: ExperimentTracker):
    report = f"""
    # ì‹¤í—˜ ë³´ê³ ì„œ: {tracker.experiment_name}
    
    ## ì‹¤í—˜ ê°œìš”
    - ì‹¤í—˜ ì¼ì‹œ: {datetime.now()}
    - ì‹¤í—˜ íšŸìˆ˜: {len(tracker.results)}
    
    ## ì£¼ìš” ê²°ê³¼
    {tracker.compare_models().to_string()}
    
    ## ê¶Œì¥ì‚¬í•­
    - ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {tracker.get_best_model()}
    - ê°œì„  í¬ì¸íŠ¸: {tracker.get_improvement_suggestions()}
    """
    
    with open(f"reports/{tracker.experiment_name}_report.md", "w") as f:
        f.write(report)
```

---

ì´ ê°€ì´ë“œë¥¼ í†µí•´ AI ì—°êµ¬ì›ë“¤ì´ PMark3 ì‹œìŠ¤í…œì„ ê¹Šì´ ì´í•´í•˜ê³ , íš¨ê³¼ì ì¸ ì‹¤í—˜ì„ í†µí•´ ì‹œìŠ¤í…œì„ ê°œì„ í•  ìˆ˜ ìˆê¸°ë¥¼ ë°”ëë‹ˆë‹¤. ê° ì‹¤í—˜ ê²°ê³¼ëŠ” ê°œë°œíŒ€ê³¼ ê³µìœ í•˜ì—¬ Production ì‹œìŠ¤í…œì— ë°˜ì˜í•´ ì£¼ì„¸ìš”. 