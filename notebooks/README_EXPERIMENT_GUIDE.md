# PMark2-Dev AI 연구팀 실험 가이드

이 문서는 AI 연구팀이 각 모듈별로 로직, 구조, 성능 개선을 위한 실험을 진행할 수 있도록 작성된 가이드입니다.

---

## 📋 실험 노트북 목록

### 1. **01_parser_experiment.ipynb** - 자연어 입력 파서 실험
- **목적**: 사용자 입력 파싱 로직 개선
- **실제 코드**: `backend/app/agents/parser.py`
- **실험 대상**: LLM 모델, 프롬프트 엔지니어링, 시나리오 분기 로직
- **교체 가능 요소**: OpenAI ↔ HuggingFace, GPT-3.5 ↔ GPT-4

### 2. **02_normalizer_experiment.ipynb** - 용어 정규화 엔진 실험
- **목적**: 용어 정규화 정확도 및 성능 향상
- **실제 코드**: `backend/app/logic/normalizer.py`
- **실험 대상**: 정규화 알고리즘, 표준 용어 사전, 유사도 계산
- **교체 가능 요소**: LLM 기반 ↔ Rule-based ↔ 임베딩 기반

### 3. **03_recommender_experiment.ipynb** - 추천 엔진 실험
- **목적**: 추천 알고리즘 및 유사도 계산 개선
- **실제 코드**: `backend/app/logic/recommender.py`
- **실험 대상**: 추천 알고리즘, 유사도 계산, 벡터 검색
- **교체 가능 요소**: 문자열 매칭 ↔ 벡터 임베딩 ↔ 협업 필터링

### 4. **04_database_experiment.ipynb** - 데이터베이스 연동 실험
- **목적**: DB 성능 최적화 및 새로운 DB 기술 도입
- **실제 코드**: `backend/app/database.py`
- **실험 대상**: 쿼리 최적화, 인덱싱, 벡터 DB 연동
- **교체 가능 요소**: SQLite ↔ PostgreSQL ↔ 벡터 DB (FAISS, Pinecone 등)

### 5. **05_vector_embedding_experiment.ipynb** - 벡터 임베딩 실험
- **목적**: 벡터 임베딩 모델 및 검색 시스템 개선
- **실제 코드 적용**: 모든 모듈에 벡터 검색 기능 추가
- **실험 대상**: 임베딩 모델, 벡터 DB, 검색 알고리즘
- **교체 가능 요소**: OpenAI embeddings ↔ SentenceTransformers ↔ Cohere

### 6. **06_agent_flow_experiment.ipynb** - 전체 시스템 플로우 실험
- **목적**: 시스템 전체 동작 흐름 최적화
- **실제 코드**: `backend/app/agents/`, `backend/app/api/`
- **실험 대상**: Agent 패턴, 플로우 최적화, 에러 처리
- **교체 가능 요소**: 순차 처리 ↔ 병렬 처리, 동기 ↔ 비동기

### 7. **07_custom_module_test.ipynb** - 자유 실험 템플릿
- **목적**: 새로운 아이디어 자유 실험
- **실험 대상**: 새로운 알고리즘, 외부 API, 성능 최적화
- **활용 방법**: 연구원 개별 실험용

---

## 🚀 실험 시작 방법

### 1. 환경 설정
```bash
# 프로젝트 루트 디렉토리에서
cd notebooks/

# Jupyter Lab 실행
jupyter lab
```

### 2. 노트북 선택 및 실행
1. 관심 있는 모듈의 노트북 선택
2. 첫 번째 셀부터 순차적으로 실행
3. API 키 등 필요한 설정 값 입력

### 3. 실험 진행
1. 기본 코드 이해 및 실행
2. 실험하고 싶은 부분 수정
3. 결과 비교 및 분석
4. 성능 측정 및 벤치마킹

---

## 📊 실험 결과 반영 방법

### 1. 개선된 로직 반영
```python
# 실험에서 개선된 함수를 실제 프로젝트 파일에 복사/치환
# 예: parser.py의 _create_scenario_1_prompt() 메서드 개선 시
```

### 2. 새로운 의존성 추가
```python
# requirements.txt에 새로운 패키지 추가
# config.py에 새로운 설정 추가
```

### 3. 새로운 모듈 추가
```python
# backend/app/ 디렉토리에 새로운 파일 생성
# 기존 모듈에서 새로운 모듈 import 및 사용
```

### 4. 설정 파일 수정
```python
# config.py에 새로운 모델/API 설정 추가
# 환경변수 또는 설정 파일 업데이트
```

---

## ⚠️ 실험 시 주의사항

### 1. API 키 관리
- OpenAI, HuggingFace 등의 API 키를 안전하게 관리
- 비용이 발생할 수 있는 API 사용 시 주의
- 무료 티어 한도 확인

### 2. 성능 고려사항
- 대량 데이터 처리 시 메모리 사용량 확인
- LLM 호출 횟수 최소화 (비용 절약)
- 로컬 모델 사용 시 GPU 메모리 확인

### 3. 코드 품질
- 실험 코드도 가독성 있게 작성
- 주석을 통한 실험 의도 명시
- 결과를 재현할 수 있도록 시드 설정

### 4. 버전 관리
- 실험 전 현재 코드 백업
- Git branch를 활용한 실험 관리
- 실험 결과를 별도 브랜치에 커밋

---

## 📈 성능 측정 및 평가

### 1. 정확도 측정
```python
# 파서 정확도: 파싱 결과의 정확성
# 정규화 정확도: 표준 용어 매칭 정확성
# 추천 정확도: 사용자 만족도 기반
```

### 2. 성능 측정
```python
# 응답 시간: API 호출부터 결과 반환까지
# 처리량: 단위 시간당 처리 가능한 요청 수
# 리소스 사용량: CPU, 메모리, GPU 사용률
```

### 3. 비용 분석
```python
# API 호출 비용: OpenAI, HuggingFace 등
# 인프라 비용: 서버, 스토리지, 네트워크
# 개발 시간: 구현 및 유지보수 시간
```

---

## 🔄 실험 워크플로우

### 1. 실험 계획 수립
1. 개선하고자 하는 모듈 선택
2. 실험 목표 및 가설 설정
3. 성공 지표 정의

### 2. 실험 실행
1. 관련 노트북 열기
2. 기본 코드 이해 및 실행
3. 가설에 따른 코드 수정
4. 결과 측정 및 분석

### 3. 결과 검증
1. 여러 테스트 케이스로 검증
2. 성능 지표 측정
3. 기존 방법과 비교

### 4. 적용 및 공유
1. 검증된 개선사항을 실제 코드에 반영
2. 실험 과정 및 결과 문서화
3. 팀원들과 지식 공유

---

## 🛠️ 유용한 도구 및 라이브러리

### 1. LLM 모델
- **OpenAI**: GPT-3.5, GPT-4, text-embedding-ada-002
- **HuggingFace**: Transformers, BERT, T5, GPT-2
- **로컬 모델**: Ollama, Llama.cpp

### 2. 벡터 DB
- **FAISS**: 페이스북의 오픈소스 벡터 검색 라이브러리
- **Pinecone**: 클라우드 기반 벡터 DB 서비스
- **Chroma**: 오픈소스 임베딩 데이터베이스
- **Weaviate**: 벡터 검색 엔진

### 3. 성능 측정
- **time**: 실행 시간 측정
- **memory_profiler**: 메모리 사용량 측정
- **pytest**: 테스트 자동화
- **locust**: 부하 테스트

### 4. 데이터 처리
- **pandas**: 데이터 분석 및 조작
- **numpy**: 수치 계산
- **scikit-learn**: 머신러닝 알고리즘
- **matplotlib/seaborn**: 데이터 시각화

---


## 📚 참고 자료

1. **프로젝트 문서**
   - `docs/SYSTEM_ARCHITECTURE.md`: 시스템 아키텍처
   - `docs/API_DOCUMENTATION.md`: API 문서
   - `docs/DEVELOPMENT_GUIDE.md`: 개발 가이드

2. **외부 문서**
   - OpenAI API 문서
   - HuggingFace Transformers 문서
   - LangChain 문서 (Agent 패턴 참고)

---

## 📝 실험 로그 템플릿

각 실험 후 아래 템플릿으로 로그를 작성하여 팀원들과 공유하면 도움이 돼요(동욱):

```markdown
## 실험 로그 - [날짜]

### 실험 목적
- 개선하고자 했던 기능/성능

### 실험 내용
- 시도한 방법/알고리즘
- 사용한 도구/라이브러리

### 실험 결과
- 성능 지표 (정확도, 속도 등)
- 기존 방법 대비 개선점

### 실제 적용 여부
- [ ] 실제 코드에 반영 완료
- [ ] 추가 검증 필요
- [ ] 적용하지 않음 (이유: ...)

### 학습 내용
- 실험을 통해 얻은 인사이트
- 향후 개선 방향
```

---

이 가이드를 참고하여 효과적인 실험을 진행하시고, 좋은 결과를 얻으시기 바랍니다! 🚀 
