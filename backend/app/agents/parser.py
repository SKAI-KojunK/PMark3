"""
PMark3 ìì—°ì–´ ì…ë ¥ íŒŒì„œ ëª¨ë“ˆ

=== ëª¨ë“ˆ ê°œìš” ===
ì‚¬ìš©ìì˜ ìì—°ì–´ ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜í•˜ëŠ” í•µì‹¬ ëª¨ë“ˆì…ë‹ˆë‹¤.
OpenAI GPT-4ë¥¼ í™œìš©í•˜ì—¬ ì‹œë‚˜ë¦¬ì˜¤ íŒë‹¨ ë° ì •ë³´ ì¶”ì¶œì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

=== Production ì „í™˜ ì£¼ìš” í¬ì¸íŠ¸ ===
ğŸ”„ LangGraph ë…¸ë“œ ì „í™˜: ì´ í´ë˜ìŠ¤ëŠ” LangGraphì˜ íŒŒì‹± ë…¸ë“œë¡œ ì „í™˜ë©ë‹ˆë‹¤
ğŸ¤– ë¡œì»¬ LLM ì—°ë™: OpenAI â†’ vLLM ê¸°ë°˜ Mistral 7B/Qwen3 14Bë¡œ ì „í™˜ ì˜ˆì •
ğŸ“Š ì„±ëŠ¥ ìµœì í™”: ë°°ì¹˜ ì²˜ë¦¬, ìºì‹±, ì¬ì‹œë„ ë¡œì§ ì¶”ê°€ í•„ìš”
ğŸ” ë²¡í„° ê²€ìƒ‰ í†µí•©: ì •ê·œí™” ë¡œì§ê³¼ ë²¡í„° ì„ë² ë”© ì‹œìŠ¤í…œ ì—°ë™ ì˜ˆì •

=== ì—°ê³„ ì‹œìŠ¤í…œ ===
â€¢ ì…ë ¥: chat.py (ì‚¬ìš©ì ë©”ì‹œì§€) â†’ session_manager.py (ì»¨í…ìŠ¤íŠ¸)
â€¢ ì²˜ë¦¬: normalizer.py (ìš©ì–´ ì •ê·œí™”) â†’ database.py (ê²€ì¦)  
â€¢ ì¶œë ¥: recommender.py (ì¶”ì²œ ì—”ì§„) â†’ response_generator.py

=== AI ì—°êµ¬ì› ì‹¤í—˜ í¬ì¸íŠ¸ ===
1. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§: _create_scenario_1_prompt() ìµœì í™”
2. ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ: GPT-4 vs Mistral 7B vs Qwen3 14B
3. ì‹œë‚˜ë¦¬ì˜¤ ë¶„ê¸° ë¡œì§: _determine_scenario() ê°œì„ 
4. ì •í™•ë„ ì¸¡ì •: confidence ì ìˆ˜ ì‚°ì • ì•Œê³ ë¦¬ì¦˜ ê°œì„ 

=== ê°œë°œíŒ€ ì°¸ê³ ì‚¬í•­ ===
â€¢ LangGraph ì „í™˜ ì‹œ ê° ë©”ì„œë“œë¥¼ ë…ë¦½ì ì¸ ë…¸ë“œë¡œ ë¶„ë¦¬
â€¢ Azure ë°°í¬ ì‹œ í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ì„¤ì • ê´€ë¦¬ í•„ìš”
â€¢ Production ëª¨ë‹ˆí„°ë§: íŒŒì‹± ì •í™•ë„, ì‘ë‹µ ì‹œê°„, ì—ëŸ¬ìœ¨ ì¶”ì 
â€¢ ë©€í‹°í„´ ëŒ€í™” ì§€ì›: ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ ë° ì»¨í…ìŠ¤íŠ¸ ëˆ„ì  ë¡œì§
"""

import re
from openai import OpenAI
from typing import Dict, List, Optional, Tuple
from ..config import Config
from ..models import ParsedInput
from ..logic.normalizer import normalizer
import json
from difflib import SequenceMatcher

class InputParser:
    """
    ìì—°ì–´ ì…ë ¥ íŒŒì„œ í•µì‹¬ í´ë˜ìŠ¤
    
    === í˜„ì¬ ì•„í‚¤í…ì²˜ì—ì„œì˜ ì—­í•  ===
    ğŸ¯ ì‹œë‚˜ë¦¬ì˜¤ íŒë‹¨: S1(ìì—°ì–´) vs S2(ITEMNO) vs S3(ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜)
    ğŸ” ì •ë³´ ì¶”ì¶œ: location, equipment_type, status_code, priority
    ğŸ¤ ì •ê·œí™” ì—°ë™: normalizer.pyì™€ í˜‘ë ¥í•˜ì—¬ í‘œì¤€ ìš©ì–´ ë§¤í•‘
    ğŸ“Š ì‹ ë¢°ë„ í‰ê°€: ì¶”ì¶œ ê²°ê³¼ì˜ confidence ì ìˆ˜ ì‚°ì •
    
    === Production ì „í™˜ ì‹œ ë³€ê²½ì‚¬í•­ ===
    ğŸ”„ LangGraph ë…¸ë“œí™”:
    - parse_input_with_context() â†’ parsing_node()
    - _determine_scenario() â†’ scenario_router_node() 
    - ê° ì‹œë‚˜ë¦¬ì˜¤ë³„ ë…ë¦½ ë…¸ë“œ ë¶„ë¦¬
    
    ğŸ¤– ë¡œì»¬ LLM í†µí•©:
    - OpenAI í´ë¼ì´ì–¸íŠ¸ â†’ vLLM ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ
    - ë°°ì¹˜ ì²˜ë¦¬ ì§€ì› (ë™ì¼ ì„¸ì…˜ ë‚´ ë‹¤ì¤‘ ìš”ì²­)
    - ìë™ ì¬ì‹œë„ ë° íƒ€ì„ì•„ì›ƒ ê´€ë¦¬
    
    ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”:
    - ê²°ê³¼ ìºì‹± (Redis/Azure Cache ì—°ë™)
    - ì‘ë‹µ ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼
    - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 
    
    === ì—°ê³„ ì§€ì  ë¶„ì„ ===
    â¬…ï¸ ì…ë ¥ë‹¨: 
    - api/chat.py: chat_endpoint() â†’ parse_input()
    - session_manager.py: ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì œê³µ
    
    â¡ï¸ ì¶œë ¥ë‹¨:
    - logic/normalizer.py: _normalize_extracted_terms() í˜¸ì¶œ
    - logic/recommender.py: ParsedInput ê°ì²´ ì „ë‹¬
    - database.py: ê²€ìƒ‰ í•„í„° ìƒì„±
    
    === AI ì—°êµ¬ì› ì‹¤í—˜ ê°€ì´ë“œ ===
    ğŸ“ í”„ë¡¬í”„íŠ¸ ìµœì í™”: notebooks/01_parser_experiment.ipynb í™œìš©
    ğŸ”¬ ëª¨ë¸ ë¹„êµ: GPT-4 vs Mistral 7B vs Qwen3 14B ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹
    ğŸ“Š ì •í™•ë„ ì¸¡ì •: Ground Truth ë°ì´í„°ì…‹ ê¸°ë°˜ í‰ê°€
    ğŸ›ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°: temperature, max_tokens, top_p ì¡°ì • ì‹¤í—˜
    
    === ê°œë°œíŒ€ êµ¬í˜„ ê°€ì´ë“œ ===
    ğŸ—ï¸ ì•„í‚¤í…ì²˜ ì„¤ê³„:
    - ìƒíƒœ ê´€ë¦¬: PMark3WorkflowState í™œìš©
    - ì—ëŸ¬ ì²˜ë¦¬: ì¬ì‹œë„ ë¡œì§ ë° í´ë°± ë©”ì»¤ë‹ˆì¦˜
    - ëª¨ë‹ˆí„°ë§: íŒŒì‹± ì •í™•ë„, ì‘ë‹µ ì‹œê°„, ì—ëŸ¬ìœ¨ ì¶”ì 
    
    ğŸš€ ë°°í¬ ê³ ë ¤ì‚¬í•­:
    - í™˜ê²½ë³„ ì„¤ì •: dev/staging/prod ë¶„ë¦¬
    - ìŠ¤ì¼€ì¼ë§: HPA ê¸°ë°˜ ìë™ í™•ì¥
    - ë³´ì•ˆ: API í‚¤ ê´€ë¦¬ (Azure Key Vault)
    """
    
    def __init__(self):
        """
        ì…ë ¥ íŒŒì„œ ì´ˆê¸°í™”
        
        ì„¤ì •:
        - OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        - ëª¨ë¸ ì„¤ì •
        """
        self.client = OpenAI(api_key=Config.OPENAI_API_KEY)
        
        # ITEMNO íŒ¨í„´ (ì±„ë²ˆ ê·œì¹™)
        self.itemno_patterns = [
            r'\b[A-Z]{2,4}-\d{5}\b',  # ì˜ˆ: RFCC-00123
            r'\b[A-Z]-\w+\b',         # ì˜ˆ: Y-MV1035
            r'\b\d{5}-[A-Z]{2}-\d+-[A-Z]\b',  # ì˜ˆ: 44043-CA1-6-P
            r'\b\d{4,}-[A-Z]{2}-\d+-[A-Z]\b',  # ì˜ˆ: 44043-CA1-6-P (ë” ìœ ì—°í•œ íŒ¨í„´)
            r'\b[A-Z]{2}-\w+-\d{2}\b',  # ì˜ˆ: SW-CV1307-02
        ]
        
        # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ
        self.priority_keywords = {
            "ê¸´ê¸‰ì‘ì—…": ["ê¸´ê¸‰", "ê¸´ê¸‰ì‘ì—…", "urgent", "emergency"],
            "ìš°ì„ ì‘ì—…": ["ìš°ì„ ", "ìš°ì„ ì‘ì—…", "priority", "high"],
            "ì¼ë°˜ì‘ì—…": ["ì¼ë°˜", "ì¼ë°˜ì‘ì—…", "normal", "regular"]
        }
    
    def parse_input(self, user_input: str, conversation_history: list = None) -> ParsedInput:
        """
        ì‚¬ìš©ì ì…ë ¥ì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
            
        Returns:
            ParsedInput: íŒŒì‹±ëœ êµ¬ì¡°í™”ëœ ë°ì´í„°
            
        ì‚¬ìš©ì²˜:
        - chat.py: chat_endpoint()ì—ì„œ ì‚¬ìš©ì ì…ë ¥ ë¶„ì„
        - recommender.py: RecommendationEngineì—ì„œ íŒŒì‹± ê²°ê³¼ í™œìš©
        
        ì—°ê³„ íŒŒì¼:
        - models.py: ParsedInput ëª¨ë¸ë¡œ ë°˜í™˜
        - logic/normalizer.py: _normalize_extracted_terms()ì—ì„œ ìš©ì–´ ì •ê·œí™”
        
        ì˜ˆì‹œ:
        - "1PE ì••ë ¥ë² ì ¤ ê³ ì¥" â†’ ParsedInput(scenario="S1", location="No.1 PE", equipment_type="Pressure Vessel", status_code="ê³ ì¥")
        - "ITEMNO 12345 ì‘ì—…ìƒì„¸" â†’ ParsedInput(scenario="S2", itemno="12345")
        
        ë‹´ë‹¹ì ìˆ˜ì • ê°€ì´ë“œ:
        - ì‹œë‚˜ë¦¬ì˜¤ íŒë‹¨ ë¡œì§ì€ ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ ì¡°ì •
        - ìƒˆë¡œìš´ í•„ë“œ ì¶”ì¶œ ì‹œ _create_scenario_1_prompt() ìˆ˜ì • í•„ìš”
        - confidence ì ìˆ˜ëŠ” LLM ì‘ë‹µì˜ ì‹ ë¢°ë„ë¥¼ ë°˜ì˜
        """
        try:
            # ì‹œë‚˜ë¦¬ì˜¤ íŒë‹¨
            scenario = self._determine_scenario(user_input)
            
            if scenario == "S1":
                # ì‹œë‚˜ë¦¬ì˜¤ 1: ìì—°ì–´ë¡œ ì‘ì—… ìš”ì²­
                return self._parse_scenario_1(user_input)
            elif scenario == "S2":
                # ì‹œë‚˜ë¦¬ì˜¤ 2: ITEMNOë¡œ ì‘ì—… ìƒì„¸ ìš”ì²­
                return self._parse_scenario_2(user_input)
            else:
                # ê¸°ë³¸ ì‹œë‚˜ë¦¬ì˜¤
                return self._parse_default_scenario(user_input)
                
        except Exception as e:
            print(f"ì…ë ¥ íŒŒì‹± ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return ParsedInput(
                scenario="S1",
                location=None,
                equipment_type=None,
                status_code=None,
                priority=None,
                itemno=None,
                confidence=0.0
            )
    
    def parse_input_with_context(self, user_input: str, conversation_history: list = None, session_id: str = None) -> ParsedInput:
        """
        ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ì…ë ¥ íŒŒì‹± (PMark3 ê³ ê¸‰ ê¸°ëŠ¥)
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
            conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬
            session_id: ì„¸ì…˜ ID
            
        Returns:
            ParsedInput: ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°˜ì˜í•œ íŒŒì‹± ê²°ê³¼
        """
        try:
            # ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ
            from ..session_manager import session_manager
            session_state = session_manager.get_session(session_id) if session_id else None
            
            if session_state and session_state.accumulated_clues.has_any_clue():
                # ê¸°ì¡´ ëˆ„ì  ë‹¨ì„œê°€ ìˆì„ ë•Œë§Œ ì»¨í…ìŠ¤íŠ¸ íŒŒì‹± ì‚¬ìš©
                return self._parse_scenario_1_with_context(user_input, conversation_history, session_state.accumulated_clues)
            else:
                # ì²« ë²ˆì§¸ ì…ë ¥ì´ê±°ë‚˜ ëˆ„ì  ë‹¨ì„œê°€ ì—†ìœ¼ë©´ ì¼ë°˜ íŒŒì‹± ì‚¬ìš©
                print(f"ëˆ„ì  ë‹¨ì„œê°€ ì—†ì–´ ì¼ë°˜ íŒŒì‹± ì‚¬ìš©")
                return self.parse_input(user_input, conversation_history)
                
        except Exception as e:
            print(f"ì»¨í…ìŠ¤íŠ¸ íŒŒì‹± ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ íŒŒì‹±ìœ¼ë¡œ fallback
            return self.parse_input(user_input, conversation_history)

    def _determine_scenario(self, user_input: str) -> str:
        """
        ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ì‹œë‚˜ë¦¬ì˜¤ íŒë‹¨
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
            
        Returns:
            ì‹œë‚˜ë¦¬ì˜¤ íƒ€ì… ("S1", "S2", "default")
            
        íŒë‹¨ ê¸°ì¤€:
        - S1: ìì—°ì–´ë¡œ ì‘ì—… ìš”ì²­ (ìœ„ì¹˜, ì„¤ë¹„, í˜„ìƒ ë“± í¬í•¨)
        - S2: ITEMNOë¡œ ì‘ì—… ìƒì„¸ ìš”ì²­ (ITEMNO í¬í•¨)
        - default: ê¸°íƒ€
        
        ë‹´ë‹¹ì ìˆ˜ì • ê°€ì´ë“œ:
        - ì‹œë‚˜ë¦¬ì˜¤ íŒë‹¨ ê¸°ì¤€ì€ ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ ì¡°ì •
        - ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ ì¶”ê°€ë¡œ ë” ì •í™•í•œ íŒë‹¨ ê°€ëŠ¥
        """
        # ITEMNO íŒ¨í„´ í™•ì¸ (ì‹œë‚˜ë¦¬ì˜¤ 2) - ë” ì •í™•í•œ íŒ¨í„´ ë§¤ì¹­
        itemno_patterns = [
            r'ITEMNO\s*\d+',  # ITEMNO 12345
            r'\b\d{4,}-\w+',  # 44043-CA1-6-P
            r'\b[A-Z]-\w+\d+',  # Y-MV1035
            r'\b[A-Z]{2,4}-\w+',  # PE-SE1304B
            r'\b[A-Z]{2,4}\d+',  # SW-CV1307-02
            r'\b\d{5,}',  # 5ìë¦¬ ì´ìƒ ìˆ«ì
            r'"[^"]*"',  # ë”°ì˜´í‘œë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ì½”ë“œ
        ]
        
        for pattern in itemno_patterns:
            if re.search(pattern, user_input, re.IGNORECASE):
                return "S2"
        
        # ìì—°ì–´ ì‘ì—… ìš”ì²­ íŒ¨í„´ í™•ì¸ (ì‹œë‚˜ë¦¬ì˜¤ 1)
        # ë” í¬ê´„ì ì¸ í‚¤ì›Œë“œ ëª©ë¡
        keywords = [
            'ê³ ì¥', 'ëˆ„ì„¤', 'ì‘ë™ë¶ˆëŸ‰', 'ì ê²€', 'ì •ë¹„', 'ì••ë ¥', 'ì˜¨ë„', 'ë°¸ë¸Œ', 'íŒí”„', 'íƒ±í¬',
            'ë² ì ¤', 'ë² ì…€', 'vessel', 'pressure', 'valve', 'motor', 'pump', 'tank',
            'ì»¨ë² ì´ì–´', 'conveyor', 'ì—´êµí™˜', 'heat', 'exchanger', 'í•„í„°', 'filter',
            'ì••ì¶•', 'compressor', 'íŒ¬', 'fan', 'ë¸”ë¡œì›Œ', 'blower', 'ë“œëŸ¼', 'drum',
            'ë°˜ì‘', 'reactor', 'ë¶„ì„', 'analyzer', 'ëˆ„ì¶œ', 'leak', 'bolting',
            'ì†ŒìŒ', 'ì§„ë™', 'ì˜¨ë„ìƒìŠ¹', 'ì••ë ¥ìƒìŠ¹', 'ê²°í•¨', 'ìˆ˜ëª…ì†Œì§„'
        ]
        
        if any(keyword.lower() in user_input.lower() for keyword in keywords):
            return "S1"
        
        # ê¸°ë³¸ê°’: ì‹œë‚˜ë¦¬ì˜¤ 1 (ìì—°ì–´ ì…ë ¥ìœ¼ë¡œ ê°€ì •)
        return "S1"
    
    def _parse_scenario_1(self, user_input: str, conversation_history: list = None) -> ParsedInput:
        """
        ì‹œë‚˜ë¦¬ì˜¤ 1 íŒŒì‹±: ìì—°ì–´ë¡œ ì‘ì—… ìš”ì²­
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
            
        Returns:
            ParsedInput: íŒŒì‹±ëœ êµ¬ì¡°í™”ëœ ë°ì´í„°
            
        ì¶”ì¶œ ì •ë³´:
        - location: ìœ„ì¹˜/ê³µì •
        - equipment_type: ì„¤ë¹„ìœ í˜•
        - status_code: í˜„ìƒì½”ë“œ
        - priority: ìš°ì„ ìˆœìœ„
        
        ë‹´ë‹¹ì ìˆ˜ì • ê°€ì´ë“œ:
        - ì¶”ì¶œ í•„ë“œ ë³€ê²½ ì‹œ í”„ë¡¬í”„íŠ¸ ìˆ˜ì • í•„ìš”
        - ëŒ€í™” íˆìŠ¤í† ë¦¬ í™œìš© ë¡œì§ ê°œì„  ê°€ëŠ¥
        - ì •ê·œí™” ë¡œì§ì€ _normalize_extracted_terms()ì—ì„œ ì²˜ë¦¬
        """
        try:
            # LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_scenario_1_prompt(user_input, conversation_history)
            
            # LLM í˜¸ì¶œ (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
            import time
            start_time = time.time()
            
            response = self.client.chat.completions.create(
                model=Config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì„¤ë¹„ê´€ë¦¬ ì‹œìŠ¤í…œì˜ ì…ë ¥ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,  # ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì€ temperature
                max_tokens=500
            )
            
            # íƒ€ì„ì•„ì›ƒ ì²´í¬
            if time.time() - start_time > 15:
                print("LLM í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ")
                return self._create_default_parsed_input()
            
            result_text = response.choices[0].message.content.strip()
            
            # ì‘ë‹µ íŒŒì‹±
            parsed_data = self._parse_llm_response(result_text)
            
            # ì¶”ì¶œëœ ìš©ì–´ ì •ê·œí™”
            normalized_data = self._normalize_extracted_terms(parsed_data)
            
            return ParsedInput(
                scenario="S1",
                location=normalized_data.get('location'),
                equipment_type=normalized_data.get('equipment_type'),
                status_code=normalized_data.get('status_code'),
                priority=normalized_data.get('priority'),  # Noneì¼ ìˆ˜ ìˆìŒ - ì¶”í›„ DBì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ ê¸°ë³¸ê°’ ì„¤ì •
                itemno=None,
                confidence=parsed_data.get('confidence', 0.0)
            )
            
        except Exception as e:
            print(f"ì‹œë‚˜ë¦¬ì˜¤ 1 íŒŒì‹± ì˜¤ë¥˜: {e}")
            return self._create_default_parsed_input()

    def _parse_scenario_1_with_context(self, user_input: str, conversation_history: list, accumulated_clues) -> ParsedInput:
        """
        ëˆ„ì ëœ ë‹¨ì„œì™€ í•¨ê»˜ ì‹œë‚˜ë¦¬ì˜¤ 1 íŒŒì‹±
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥
            conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬
            accumulated_clues: ëˆ„ì ëœ ë‹¨ì„œë“¤
            
        Returns:
            ParsedInput: ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°˜ì˜í•œ íŒŒì‹± ê²°ê³¼
        """
        try:
            print(f"ì»¨í…ìŠ¤íŠ¸ íŒŒì‹± ì‹œì‘: {user_input[:50]}...")
            print(f"ëˆ„ì  ë‹¨ì„œ - ìœ„ì¹˜: {accumulated_clues.location}, ì„¤ë¹„: {accumulated_clues.equipment_type}, í˜„ìƒ: {accumulated_clues.status_code}")
            
            # ì»¨í…ìŠ¤íŠ¸ í¬í•¨ í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_scenario_1_context_prompt(user_input, conversation_history, accumulated_clues)
            
            # LLM í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=Config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì„¤ë¹„ê´€ë¦¬ ì‹œìŠ¤í…œì˜ ë©€í‹°í„´ ëŒ€í™” ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•˜ì—¬ ì…ë ¥ì„ ë¶„ì„í•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=500
            )
            
            result_text = response.choices[0].message.content.strip()
            print(f"LLM ì‘ë‹µ: {result_text}")
            
            # ì‘ë‹µ íŒŒì‹±
            parsed_data = self._parse_llm_response(result_text)
            
            # ì¶”ì¶œëœ ìš©ì–´ ì •ê·œí™”
            normalized_data = self._normalize_extracted_terms(parsed_data)
            
            # ParsedInput ê°ì²´ ìƒì„±
            parsed_input = ParsedInput(
                scenario="S1",
                location=normalized_data.get("location"),
                equipment_type=normalized_data.get("equipment_type"),
                status_code=normalized_data.get("status_code"),
                priority=normalized_data.get("priority"),  # Noneì¼ ìˆ˜ ìˆìŒ - ì¶”í›„ DBì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ ê¸°ë³¸ê°’ ì„¤ì •
                confidence=normalized_data.get("confidence", 0.8)
            )
            
            print(f"ì»¨í…ìŠ¤íŠ¸ íŒŒì‹± ì™„ë£Œ: {parsed_input}")
            return parsed_input
            
        except Exception as e:
            print(f"ì»¨í…ìŠ¤íŠ¸ íŒŒì‹± ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            # ê¸°ë³¸ íŒŒì‹±ìœ¼ë¡œ fallback
            return self._parse_scenario_1(user_input, conversation_history)

    def _create_scenario_1_prompt(self, user_input: str, conversation_history: list = None) -> str:
        """
        ì‹œë‚˜ë¦¬ì˜¤ 1ìš© LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
            
        Returns:
            LLM í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
            
        ë‹´ë‹¹ì ìˆ˜ì • ê°€ì´ë“œ:
        - ì¶”ì¶œ í•„ë“œ ë³€ê²½ ì‹œ ì´ í”„ë¡¬í”„íŠ¸ ìˆ˜ì • í•„ìš”
        - ì˜ˆì‹œëŠ” ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ë°˜ì˜í•˜ì—¬ ì—…ë°ì´íŠ¸
        - ëŒ€í™” íˆìŠ¤í† ë¦¬ í™œìš© ë¡œì§ ê°œì„  ê°€ëŠ¥
        """
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = ""
        if conversation_history and len(conversation_history) > 0:
            context = "ëŒ€í™” íˆìŠ¤í† ë¦¬:\n"
            for msg in conversation_history[-3:]:  # ìµœê·¼ 3ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš©
                context += f"{msg['role']}: {msg['content']}\n"
            context += "\n"
        
        return f"""
{context}ë‹¤ìŒ ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì„¤ë¹„ê´€ë¦¬ ì‘ì—… ìš”ì²­ ê´€ë ¨ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

**ì‚¬ìš©ì ì…ë ¥**: {user_input}

**ì¶”ì¶œí•´ì•¼ í•  ì •ë³´**:
1. location: ìœ„ì¹˜/ê³µì • (ì˜ˆ: No.1 PE, No.2 PE, ì„ìœ ì œí’ˆë°°í•©/ì €ì¥, í•©ì„±ìˆ˜ì§€ í¬ì¥, RFCC, 1ì°½ê³  #7Line, 2ì°½ê³  #8Line, ê³µí†µ ì‹œì„¤)
   - ì‚¬ìš©ìê°€ "ìœ„ì¹˜" ë˜ëŠ” "ê³µì •"ìœ¼ë¡œ ì–¸ê¸‰í•œ ë‚´ìš©ì„ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì¶œ
   - ìœ„ì¹˜ ì •ë³´ê°€ ì—†ìœ¼ë©´ ê³µì •ëª…ì„ ìœ„ì¹˜ë¡œ ì‚¬ìš©
2. equipment_type: ì„¤ë¹„ìœ í˜• (ì˜ˆ: Pressure Vessel, Motor Operated Valve, Conveyor, Pump, Heat Exchanger, Valve, Control Valve, Tank, Storage Tank, Drum, Filter, Reactor, Compressor, Fan, Blower)
3. status_code: í˜„ìƒì½”ë“œ (ì˜ˆ: ê³ ì¥, ëˆ„ì„¤, ì‘ë™ë¶ˆëŸ‰, ì†ŒìŒ, ì§„ë™, ì˜¨ë„ìƒìŠ¹, ì••ë ¥ìƒìŠ¹, ì£¼ê¸°ì  ì ê²€/ì •ë¹„, ê³ ì¥.ê²°í•¨.ìˆ˜ëª…ì†Œì§„)
4. priority: ìš°ì„ ìˆœìœ„ (ì„ íƒì‚¬í•­ - ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰í•œ ê²½ìš°ì—ë§Œ ì¶”ì¶œ)
   - ê¸´ê¸‰ì‘ì—…: "ê¸´ê¸‰", "ê¸´ê¸‰ì‘ì—…", "ìµœìš°ì„ ", "urgent", "emergency"
   - ìš°ì„ ì‘ì—…: "ìš°ì„ ", "ìš°ì„ ì‘ì—…", "priority", "high priority"
   - ì¼ë°˜ì‘ì—…: "ì¼ë°˜", "ì¼ë°˜ì‘ì—…", "normal", "regular"
   - ì£¼ê¸°ì‘ì—…: "ì£¼ê¸°", "ì£¼ê¸°ì‘ì—…", "ì •ê¸°", "PM", "TA"

**ì¶”ì¶œ ê·œì¹™**:
1. ë¬¸ì¥ì˜ ì–´ëŠ ìœ„ì¹˜ì— ìˆë“  í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ë‚´ìš©ì„ ì°¾ì•„ ì¶”ì¶œ
2. í•œ ë‹¨ì–´ê°€ ì•„ë‹Œ ì—¬ëŸ¬ ë‹¨ì–´ë¡œ êµ¬ì„±ëœ í‘œí˜„ë„ í•´ë‹¹ ë²”ì£¼ë¡œ ì¸ì‹
3. ìœ ì‚¬í•œ í‘œí˜„ì´ë‚˜ ë™ì˜ì–´ë„ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ë¡œ ë§¤í•‘
4. ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ ì„ íƒ
5. **ìœ„ì¹˜ ì •ë³´ê°€ ê°€ì¥ ì¤‘ìš”í•˜ë¯€ë¡œ, ìœ„ì¹˜ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì°¾ì•„ ì¶”ì¶œ**
6. **ìš°ì„ ìˆœìœ„ëŠ” ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰í•œ ê²½ìš°ì—ë§Œ ì¶”ì¶œí•˜ë©°, í•„ìˆ˜ í•­ëª©ì´ ì•„ë‹˜**
7. **í•œêµ­ì–´-ì˜ì–´ í˜¼ìš© í‘œí˜„ë„ ì •í™•íˆ ì¸ì‹** (ì˜ˆ: "Pressure Vessel/ Drum" â†’ "Pressure Vessel")
8. **ì˜¤íƒ€, ë„ì–´ì“°ê¸°, íŠ¹ìˆ˜ë¬¸ì ë¬´ì‹œí•˜ê³  ì˜ë¯¸ íŒŒì•…**

**ì‘ë‹µ í˜•ì‹**:
```json
{{
    "location": "ì¶”ì¶œëœ ìœ„ì¹˜/ê³µì •",
    "equipment_type": "ì¶”ì¶œëœ ì„¤ë¹„ìœ í˜•",
    "status_code": "ì¶”ì¶œëœ í˜„ìƒì½”ë“œ",
    "priority": "ìš°ì„ ìˆœìœ„",
    "confidence": 0.95,
    "reasoning": "ì¶”ì¶œ ì´ìœ "
}}
```

**ì˜ˆì‹œ**:
- ì…ë ¥: "No.1 PEì˜ Pressure Vessel/ Drumì— ê³ ì¥ ë°œìƒ" â†’ ì¶œë ¥: {{"location": "No.1 PE", "equipment_type": "Pressure Vessel", "status_code": "ê³ ì¥", "priority": null, "confidence": 0.95, "reasoning": "ìœ„ì¹˜ì™€ ì„¤ë¹„ìœ í˜•, í˜„ìƒì½”ë“œ ëª¨ë‘ ì¶”ì¶œ"}}
- ì…ë ¥: "ì„ìœ ì œí’ˆë°°í•©/ì €ì¥ì˜ Motor Operated Valve, ì‘ë™ë¶ˆëŸ‰. ê¸´ê¸‰ì‘ì—… ìš”ë§" â†’ ì¶œë ¥: {{"location": "ì„ìœ ì œí’ˆë°°í•©/ì €ì¥", "equipment_type": "Motor Operated Valve", "status_code": "ì‘ë™ë¶ˆëŸ‰", "priority": "ê¸´ê¸‰ì‘ì—…", "confidence": 0.95, "reasoning": "ê¸´ê¸‰ì‘ì—… ëª…ì‹œì  ì–¸ê¸‰"}}
- ì…ë ¥: "í•©ì„±ìˆ˜ì§€ í¬ì¥, Miscellaneous Equipment/ Conveyor, ê³ ì¥, ìš°ì„ ì‘ì—… ìš”ì²­" â†’ ì¶œë ¥: {{"location": "í•©ì„±ìˆ˜ì§€ í¬ì¥", "equipment_type": "Conveyor", "status_code": "ê³ ì¥", "priority": "ìš°ì„ ì‘ì—…", "confidence": 0.9, "reasoning": "ìš°ì„ ì‘ì—… ëª…ì‹œì  ì–¸ê¸‰"}}
- ì…ë ¥: "44043-CA1-6"-P, Leak ë³¼íŒ… ì‘ì—…" â†’ ì¶œë ¥: {{"location": null, "equipment_type": null, "status_code": "ëˆ„ì„¤", "priority": null, "confidence": 0.8, "reasoning": "ITEMNO íŒ¨í„´ì´ë¯€ë¡œ ì‹œë‚˜ë¦¬ì˜¤ 2ë¡œ ì²˜ë¦¬"}}

**ì£¼ì˜ì‚¬í•­**:
- ì¶”ì¶œí•  ìˆ˜ ì—†ëŠ” ì •ë³´ëŠ” nullë¡œ ì„¤ì •
- **ìš°ì„ ìˆœìœ„ëŠ” ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰í•œ ê²½ìš°ì—ë§Œ ì¶”ì¶œí•˜ë©°, ì—†ìœ¼ë©´ nullë¡œ ì„¤ì •**
- confidenceëŠ” 0.0~1.0 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ì„¤ì •
- ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì°¸ê³ í•˜ì—¬ ë§¥ë½ì„ íŒŒì•…
- ì—¬ëŸ¬ ë‹¨ì–´ë¡œ êµ¬ì„±ëœ í‘œí˜„ë„ ì •í™•íˆ ì¸ì‹
- **í•œêµ­ì–´-ì˜ì–´ í˜¼ìš© í‘œí˜„ë„ ì •í™•íˆ ì¸ì‹í•˜ê³  ì •ê·œí™”**
"""
    
    def _parse_llm_response(self, response_text: str) -> Dict:
        """
        LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ
        
        Args:
            response_text: LLM ì‘ë‹µ í…ìŠ¤íŠ¸
            
        Returns:
            íŒŒì‹±ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
            
        ë‹´ë‹¹ì ìˆ˜ì • ê°€ì´ë“œ:
        - JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í´ë°± ë¡œì§ìœ¼ë¡œ ì‘ë‹µì—ì„œ ì •ë³´ ì¶”ì¶œ
        - ì‘ë‹µ í˜•ì‹ì´ ë³€ê²½ë˜ë©´ ì´ ë©”ì„œë“œ ìˆ˜ì • í•„ìš”
        """
        try:
            # JSON ë¶€ë¶„ ì¶”ì¶œ
            json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group(1))
            else:
                # JSON ë¸”ë¡ì´ ì—†ëŠ” ê²½ìš° ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ JSONìœ¼ë¡œ íŒŒì‹± ì‹œë„
                data = json.loads(response_text)
            
            return data
            
        except Exception as e:
            print(f"LLM ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
            # í´ë°±: ê°„ë‹¨í•œ ì¶”ì¶œ ë¡œì§ìœ¼ë¡œ ì‘ë‹µì—ì„œ ì •ë³´ ì¶”ì¶œ
            return self._extract_from_text_response(response_text)
    
    def _extract_from_text_response(self, response_text: str) -> Dict:
        """
        í…ìŠ¤íŠ¸ ì‘ë‹µì—ì„œ ì •ë³´ ì¶”ì¶œ (JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í´ë°±)
        
        Args:
            response_text: LLM ì‘ë‹µ í…ìŠ¤íŠ¸
            
        Returns:
            ì¶”ì¶œëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        result = {
            'location': None,
            'equipment_type': None,
            'status_code': None,
            'priority': None,
            'confidence': 0.5,
            'reasoning': 'í…ìŠ¤íŠ¸ íŒŒì‹±ìœ¼ë¡œ ì¶”ì¶œ'
        }
        
        lines = response_text.split('\n')
        for line in lines:
            line = line.strip()
            if ':' in line:
                key, value = line.split(':', 1)
                key = key.strip().lower()
                value = value.strip()
                
                if 'null' in value.lower():
                    continue
                
                if 'location' in key and value:
                    result['location'] = value
                elif 'equipment_type' in key and value:
                    result['equipment_type'] = value
                elif 'status_code' in key and value:
                    result['status_code'] = value
                elif 'priority' in key and value:
                    result['priority'] = value
                elif 'confidence' in key and value:
                    try:
                        result['confidence'] = float(value)
                    except:
                        pass
        
        return result
    
    def _normalize_extracted_terms(self, parsed_data: Dict) -> Dict:
        """
        ì¶”ì¶œëœ ìš©ì–´ë¥¼ LLM ì •ê·œí™” ì—”ì§„ìœ¼ë¡œ ì •ê·œí™”
        
        Args:
            parsed_data: íŒŒì‹±ëœ ë°ì´í„°
            
        Returns:
            ì •ê·œí™”ëœ ë°ì´í„°
            
        ì‚¬ìš©ì²˜:
        - _parse_scenario_1()ì—ì„œ ì¶”ì¶œëœ ìš©ì–´ ì •ê·œí™”
        - database.pyì—ì„œ ê²€ìƒ‰ ì‹œ ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•´ ì‚¬ìš©
        
        ì—°ê³„ íŒŒì¼:
        - logic/normalizer.py: LLM ì •ê·œí™” ì—”ì§„ ì‚¬ìš©
        
        ë‹´ë‹¹ì ìˆ˜ì • ê°€ì´ë“œ:
        - ìƒˆë¡œìš´ ì¹´í…Œê³ ë¦¬ ì¶”ê°€ ì‹œ ì •ê·œí™” ë¡œì§ ì¶”ê°€
        - ì‹ ë¢°ë„ ì„ê³„ê°’ ì¡°ì •ìœ¼ë¡œ ì •ê·œí™” í’ˆì§ˆ ì œì–´ ê°€ëŠ¥
        """
        normalized_data = parsed_data.copy()
        
        # ì„¤ë¹„ìœ í˜• ì •ê·œí™”
        if parsed_data.get('equipment_type'):
            normalized_term, confidence = normalizer.normalize_term(
                parsed_data['equipment_type'], 'equipment'
            )
            if confidence > 0.3:  # ì‹ ë¢°ë„ ì„ê³„ê°’
                normalized_data['equipment_type'] = normalized_term
        
        # ìœ„ì¹˜ ì •ê·œí™”
        if parsed_data.get('location'):
            normalized_term, confidence = normalizer.normalize_term(
                parsed_data['location'], 'location'
            )
            if confidence > 0.3:
                normalized_data['location'] = normalized_term
        
        # í˜„ìƒì½”ë“œ ì •ê·œí™”
        if parsed_data.get('status_code'):
            normalized_term, confidence = normalizer.normalize_term(
                parsed_data['status_code'], 'status'
            )
            if confidence > 0.3:
                normalized_data['status_code'] = normalized_term
        
        # ìš°ì„ ìˆœìœ„ ì •ê·œí™”
        if parsed_data.get('priority'):
            normalized_term, confidence = normalizer.normalize_term(
                parsed_data['priority'], 'priority'
            )
            if confidence > 0.3:
                normalized_data['priority'] = normalized_term
        
        return normalized_data
    
    def _create_default_parsed_input(self) -> ParsedInput:
        """
        ê¸°ë³¸ ParsedInput ìƒì„± (ì˜¤ë¥˜ ì‹œ ì‚¬ìš©)
        
        Returns:
            ê¸°ë³¸ ParsedInput ê°ì²´
            
        ë‹´ë‹¹ì ìˆ˜ì • ê°€ì´ë“œ:
        - ê¸°ë³¸ê°’ì€ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì— ë§ê²Œ ì¡°ì • ê°€ëŠ¥
        - ì˜¤ë¥˜ ì²˜ë¦¬ ë¡œì§ ê°œì„  ê°€ëŠ¥
        """
        return ParsedInput(
            scenario="S1",
            location=None,
            equipment_type=None,
            status_code=None,
            priority=None,
            itemno=None,
            confidence=0.0
        )

    def _create_scenario_1_context_prompt(self, user_input: str, conversation_history: list, accumulated_clues) -> str:
        """
        ì»¨í…ìŠ¤íŠ¸ í¬í•¨ ì‹œë‚˜ë¦¬ì˜¤ 1 í”„ë¡¬í”„íŠ¸ ìƒì„±
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥
            conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬
            accumulated_clues: ëˆ„ì ëœ ë‹¨ì„œë“¤
            
        Returns:
            LLM í”„ë¡¬í”„íŠ¸
        """
        prompt = f"""
# ë©€í‹°í„´ ëŒ€í™” ê¸°ë°˜ ì„¤ë¹„ê´€ë¦¬ ì…ë ¥ ë¶„ì„

## ì´ì „ ëŒ€í™”ì—ì„œ ìˆ˜ì§‘ëœ ì •ë³´:
- ìœ„ì¹˜/ê³µì •: {accumulated_clues.location or "âŒ ë¯¸í™•ì¸"}
- ì„¤ë¹„ìœ í˜•: {accumulated_clues.equipment_type or "âŒ ë¯¸í™•ì¸"}
- í˜„ìƒì½”ë“œ: {accumulated_clues.status_code or "âŒ ë¯¸í™•ì¸"}
- ìš°ì„ ìˆœìœ„: {accumulated_clues.priority or "âšª ë¯¸ì§€ì • (ì„ íƒì‚¬í•­)"}

## í˜„ì¬ ì‚¬ìš©ì ì…ë ¥:
"{user_input}"

## ë¶„ì„ ì§€ì‹œì‚¬í•­:
1. í˜„ì¬ ì…ë ¥ì—ì„œ ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”
2. ì´ì „ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”
3. ì´ì „ ì •ë³´ë¥¼ ìˆ˜ì •í•˜ë ¤ëŠ” ì˜ë„ê°€ ëª…í™•í•œ ê²½ìš°ì—ë§Œ ê¸°ì¡´ ì •ë³´ë¥¼ ë®ì–´ì“°ì„¸ìš”
4. ìœ„ì¹˜ ì •ë³´ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”
5. **ì„¤ë¹„ìœ í˜• ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ë°˜ë“œì‹œ ì¶”ì¶œí•˜ì„¸ìš”**
6. **ì…ë ¥ ìˆœì„œì™€ ê´€ê³„ì—†ì´ ëª¨ë“  ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•„ ì¶”ì¶œí•˜ì„¸ìš”**

## ì¶”ì¶œí•  ì •ë³´:
- location: ìœ„ì¹˜/ê³µì •ëª… (ì˜ˆ: No.1 PE, No.2 PP, ì„ìœ ì œí’ˆë°°í•©/ì €ì¥)
- equipment_type: ì„¤ë¹„ìœ í˜• (ì˜ˆ: ì••ë ¥ë² ì ¤, Pressure Vessel, íŒí”„, Pump, ì—´êµí™˜ê¸°, Heat Exchanger, íƒ±í¬, Tank)
- status_code: í˜„ìƒì½”ë“œ (ì˜ˆ: ê³ ì¥, ëˆ„ì¶œ, ì†ŒìŒ, ì§„ë™)
- priority: ìš°ì„ ìˆœìœ„ (ì„ íƒì‚¬í•­ - ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰í•œ ê²½ìš°ì—ë§Œ ì¶”ì¶œ)
- confidence: ë¶„ì„ ì‹ ë¢°ë„ (0.0~1.0)

## ì„¤ë¹„ìœ í˜• í‚¤ì›Œë“œ ë§¤í•‘:
- "ì••ë ¥ë² ì ¤", "ë² ì ¤", "ë² ì…€", "vessel", "pressure vessel" â†’ "Pressure Vessel"
- "íŒí”„", "pump" â†’ "Pump"
- "ì—´êµí™˜", "ì—´êµí™˜ê¸°", "heat exchanger" â†’ "Heat Exchanger"
- "íƒ±í¬", "tank", "ì €ì¥íƒ±í¬" â†’ "Storage Tank"
- "ë°¸ë¸Œ", "valve", "ëª¨í„°ë°¸ë¸Œ" â†’ "Motor Operated Valve"
- "ì»¨ë² ì´ì–´", "conveyor" â†’ "Conveyor"
- "í•„í„°", "filter" â†’ "Filter"
- "ë°˜ì‘ê¸°", "reactor" â†’ "Reactor"
- "ì••ì¶•ê¸°", "compressor" â†’ "Compressor"
- "íŒ¬", "fan" â†’ "Fan"
- "ë¸”ë¡œì›Œ", "blower" â†’ "Blower"

## ì‘ë‹µ í˜•ì‹:
```json
{{
    "location": "ì¶”ì¶œëœ ìœ„ì¹˜ ë˜ëŠ” null",
    "equipment_type": "ì¶”ì¶œëœ ì„¤ë¹„ìœ í˜• ë˜ëŠ” null",
    "status_code": "ì¶”ì¶œëœ í˜„ìƒì½”ë“œ ë˜ëŠ” null",
    "priority": "ì¶”ì¶œëœ ìš°ì„ ìˆœìœ„ ë˜ëŠ” null",
    "confidence": 0.9
}}
```

## ì˜ˆì‹œ:
ì‚¬ìš©ì ì…ë ¥: "No.1 PE"
â†’ location: No.1 PE
â†’ equipment_type: null
â†’ status_code: null
â†’ priority: null
â†’ confidence: 0.9

ì‚¬ìš©ì ì…ë ¥: "ì••ë ¥ë² ì ¤"
â†’ location: null
â†’ equipment_type: Pressure Vessel
â†’ status_code: null
â†’ priority: null
â†’ confidence: 0.8

ì‚¬ìš©ì ì…ë ¥: "ê³ ì¥ë‚¬ì–´ìš”"
â†’ location: null
â†’ equipment_type: null
â†’ status_code: ê³ ì¥
â†’ priority: null
â†’ confidence: 0.7

ì‚¬ìš©ì ì…ë ¥: "íŒí”„"
â†’ location: null
â†’ equipment_type: Pump
â†’ status_code: null
â†’ priority: null
â†’ confidence: 0.8

ì‚¬ìš©ì ì…ë ¥: "ê³ ì¥ë‚œ íŒí”„" (ìˆœì„œ ë¬´ê´€)
â†’ location: null
â†’ equipment_type: Pump
â†’ status_code: ê³ ì¥
â†’ priority: null
â†’ confidence: 0.9
"""
        return prompt

    def _parse_scenario_2(self, user_input: str) -> ParsedInput:
        """
        ì‹œë‚˜ë¦¬ì˜¤ 2 íŒŒì‹±: ITEMNO ì§ì ‘ ì…ë ¥ + í˜„ìƒ ì„¤ëª… (ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­)
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
            
        Returns:
            ParsedInput: íŒŒì‹±ëœ êµ¬ì¡°í™”ëœ ë°ì´í„°
            
        ì¶”ì¶œ ì •ë³´:
        - itemno: ì‘ì—…ëŒ€ìƒ (ì„¤ë¹„ ê³ ìœ ë²ˆí˜¸) - ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­
        - status_code: í˜„ìƒì½”ë“œ (LLM ì¶”ì¶œ + ì •ê·œí™”)
        - priority: ìš°ì„ ìˆœìœ„ (LLM ì¶”ì¶œ + ì •ê·œí™”, ê¸°ë³¸ê°’: "ì¼ë°˜ì‘ì—…")
        """
        try:
            # 1. ITEMNO ì¶”ì¶œ (ì •í™•í•œ ë§¤ì¹­ â†’ ìœ ì‚¬ë„ ë§¤ì¹­)
            itemno = None
            for pattern in self.itemno_patterns:
                match = re.search(pattern, user_input)
                if match:
                    itemno = match.group(0)
                    break
            
            # 2. ì •í™•í•œ ë§¤ì¹­ì´ ì—†ìœ¼ë©´ ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ ì‹œë„
            if not itemno:
                itemno = self._find_similar_itemno(user_input)
            
            # 3. í˜„ìƒì½”ë“œì™€ ìš°ì„ ìˆœìœ„ LLM í†µí•© ì¶”ì¶œ (ì‹œë‚˜ë¦¬ì˜¤1ê³¼ ë™ì¼í•œ ë°©ì‹)
            status_code, priority = self._extract_status_and_priority_with_llm(user_input)
            
            # 4. ì¶”ì¶œëœ í˜„ìƒì½”ë“œ ì •ê·œí™”
            normalized_status_code = None
            if status_code:
                normalized_status_code, confidence = normalizer.normalize_term(status_code, 'status')
                # ì‹ ë¢°ë„ê°€ ë‚®ì€ ê²½ìš° ì›ë³¸ ì‚¬ìš©
                if confidence < 0.3:
                    normalized_status_code = status_code
            
            # 5. ì¶”ì¶œëœ ìš°ì„ ìˆœìœ„ ì •ê·œí™” (ê¸°ë³¸ê°’ "ì¼ë°˜ì‘ì—…" ì ìš©)
            normalized_priority = "ì¼ë°˜ì‘ì—…"  # ê¸°ë³¸ê°’
            if priority:
                normalized_priority_term, confidence = normalizer.normalize_term(priority, 'priority')
                # ì‹ ë¢°ë„ê°€ ì¶©ë¶„í•œ ê²½ìš° ì •ê·œí™”ëœ ê°’ ì‚¬ìš©
                if confidence > 0.3:
                    normalized_priority = normalized_priority_term
                else:
                    # ì‹ ë¢°ë„ê°€ ë‚®ì•„ë„ ì¶”ì¶œëœ ìš°ì„ ìˆœìœ„ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
                    normalized_priority = priority
            
            # 6. ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚° ê°œì„ 
            confidence = self._calculate_scenario_2_confidence(user_input, itemno, normalized_status_code, normalized_priority)
            
            return ParsedInput(
                scenario="S2",
                location=None,
                equipment_type=None,
                status_code=normalized_status_code,
                priority=normalized_priority,
                itemno=itemno,
                confidence=confidence
            )
            
        except Exception as e:
            print(f"ì‹œë‚˜ë¦¬ì˜¤ 2 íŒŒì‹± ì˜¤ë¥˜: {e}")
            return self._create_default_parsed_input()

    def _find_similar_itemno(self, user_input: str) -> Optional[str]:
        """
        ì‚¬ìš©ì ì…ë ¥ì—ì„œ ITEMNOì™€ ìœ ì‚¬í•œ íŒ¨í„´ì„ ì°¾ì•„ DBì˜ ì‘ì—…ëŒ€ìƒê³¼ ë§¤ì¹­
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
            
        Returns:
            ë§¤ì¹­ëœ ITEMNO ë˜ëŠ” None
        """
        try:
            # DBì—ì„œ ëª¨ë“  ì‘ì—…ëŒ€ìƒ ê°€ì ¸ì˜¤ê¸°
            from ..database import DatabaseManager
            db = DatabaseManager()
            
            # ì‘ì—…ëŒ€ìƒ ì»¬ëŸ¼ì—ì„œ ëª¨ë“  ê³ ìœ ê°’ ê°€ì ¸ì˜¤ê¸°
            query = "SELECT DISTINCT itemno FROM notification_history WHERE itemno IS NOT NULL AND itemno != ''"
            cursor = db.conn.cursor()
            cursor.execute(query)
            results = cursor.fetchall()
            
            if not results:
                return None
            
            # ì‚¬ìš©ì ì…ë ¥ì—ì„œ ITEMNO íŒ¨í„´ ì¶”ì¶œ ì‹œë„
            potential_itemno = self._extract_potential_itemno(user_input)
            
            if not potential_itemno:
                return None
            
            # ìœ ì‚¬ë„ ê³„ì‚° ë° ë§¤ì¹­
            best_match = None
            best_score = 0.0
            min_similarity_threshold = 0.6  # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’
            
            for row in results:
                db_itemno = row[0]
                if db_itemno:
                    # ìœ ì‚¬ë„ ê³„ì‚°
                    similarity = self._calculate_similarity(potential_itemno, db_itemno)
                    
                    if similarity > best_score and similarity >= min_similarity_threshold:
                        best_score = similarity
                        best_match = db_itemno
            
            return best_match
            
        except Exception as e:
            print(f"ìœ ì‚¬ë„ ë§¤ì¹­ ì˜¤ë¥˜: {e}")
            return None
    
    def _extract_potential_itemno(self, user_input: str) -> Optional[str]:
        """
        ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì ì¬ì ì¸ ITEMNO íŒ¨í„´ ì¶”ì¶œ (ê°œì„ ë¨)
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
            
        Returns:
            ì¶”ì¶œëœ íŒ¨í„´ ë˜ëŠ” None
        """
        # ë‹¤ì–‘í•œ ITEMNO íŒ¨í„´ ì‹œë„ (ë”°ì˜´í‘œ í¬í•¨ íŒ¨í„´ ì¶”ê°€)
        patterns = [
            r'\b\d{4,}-[A-Z]{1,4}\d*-\d+"-[A-Z]\b',  # 44043-CA1-6"-P (ë”°ì˜´í‘œ í¬í•¨)
            r'\b\d{4,}-[A-Z]{1,4}\d*-\d+-[A-Z]\b',   # 44043-CA1-6-P (ì¼ë°˜)
            r'\b\d{4,}-\w+',                          # 44043-CA1
            r'\b[A-Z]-\w+\d+',                        # Y-MV1035  
            r'\b[A-Z]{2,4}-\w+-\d{2}\b',              # SW-CV1307-02
            r'\b[A-Z]{2,4}-\w+',                      # PE-SE1304B
            r'\b\d{5,}',                              # 5ìë¦¬ ì´ìƒ ìˆ«ì
            r'\b[A-Z]{2,4}\d+',                       # PE12345
            r'"[^"]*"',                               # ë”°ì˜´í‘œë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ëª¨ë“  íŒ¨í„´
        ]
        
        for pattern in patterns:
            match = re.search(pattern, user_input, re.IGNORECASE)
            if match:
                extracted = match.group(0)
                # ë”°ì˜´í‘œë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ê²½ìš° ë”°ì˜´í‘œ ì œê±°
                if extracted.startswith('"') and extracted.endswith('"'):
                    extracted = extracted[1:-1]
                return extracted
        
        return None
    
    def _calculate_similarity(self, input_itemno: str, db_itemno: str) -> float:
        """
        ë‘ ITEMNO ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚° (ê°œì„ ë¨)
        
        Args:
            input_itemno: ì‚¬ìš©ì ì…ë ¥ ITEMNO
            db_itemno: DBì˜ ITEMNO
            
        Returns:
            ìœ ì‚¬ë„ ì ìˆ˜ (0.0 ~ 1.0)
        """
        # íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™” (ë”°ì˜´í‘œ, ê³µë°± ë“± ì œê±°)
        normalized_input = self._normalize_itemno_for_comparison(input_itemno)
        normalized_db = self._normalize_itemno_for_comparison(db_itemno)
        
        # 1. ì •ê·œí™”ëœ ì •í™•í•œ ë§¤ì¹­
        if normalized_input == normalized_db:
            return 1.0
        
        # 2. ê¸°ë³¸ ë¬¸ìì—´ ìœ ì‚¬ë„ (ì •ê·œí™”ëœ ë¬¸ìì—´ë¡œ)
        base_similarity = SequenceMatcher(None, normalized_input, normalized_db).ratio()
        
        # 3. ì¶”ê°€ ê·œì¹™ë“¤
        bonus = 0.0
        
        # ë¶€ë¶„ ë§¤ì¹­ (í¬í•¨ ê´€ê³„)
        if normalized_input in normalized_db or normalized_db in normalized_input:
            bonus += 0.2
        
        # ìˆ«ì ë¶€ë¶„ ë§¤ì¹­ (í•µì‹¬ ë¶€ë¶„)
        input_numbers = re.findall(r'\d+', normalized_input)
        db_numbers = re.findall(r'\d+', normalized_db)
        if input_numbers and db_numbers:
            number_matches = sum(1 for in_num in input_numbers 
                               for db_num in db_numbers 
                               if in_num == db_num or in_num in db_num or db_num in in_num)
            if number_matches > 0:
                bonus += 0.3 * (number_matches / max(len(input_numbers), len(db_numbers)))
        
        # ë¬¸ì ë¶€ë¶„ ë§¤ì¹­
        input_letters = re.findall(r'[A-Za-z]+', normalized_input)
        db_letters = re.findall(r'[A-Za-z]+', normalized_db)
        if input_letters and db_letters:
            letter_matches = sum(1 for in_letter in input_letters 
                               for db_letter in db_letters 
                               if in_letter.lower() == db_letter.lower())
            if letter_matches > 0:
                bonus += 0.2 * (letter_matches / max(len(input_letters), len(db_letters)))
        
        # íŒ¨í„´ êµ¬ì¡° ìœ ì‚¬ì„± (í•˜ì´í”ˆ ìœ„ì¹˜ ë“±)
        input_pattern = re.sub(r'[A-Za-z]+', 'L', re.sub(r'\d+', 'N', normalized_input))
        db_pattern = re.sub(r'[A-Za-z]+', 'L', re.sub(r'\d+', 'N', normalized_db))
        if input_pattern == db_pattern:
            bonus += 0.1
        
        return min(1.0, base_similarity + bonus)
    
    def _normalize_itemno_for_comparison(self, itemno: str) -> str:
        """
        ITEMNOë¥¼ ë¹„êµìš©ìœ¼ë¡œ ì •ê·œí™” (íŠ¹ìˆ˜ë¬¸ì ì œê±°)
        
        Args:
            itemno: ì›ë³¸ ITEMNO
            
        Returns:
            ì •ê·œí™”ëœ ITEMNO
        """
        if not itemno:
            return ""
        
        # 1. ì†Œë¬¸ì ë³€í™˜
        normalized = itemno.lower()
        
        # 2. ë”°ì˜´í‘œ ì œê±° (ì¸ì¹˜ í‘œì‹œ ë“±)
        normalized = re.sub(r'["\'`]', '', normalized)
        
        # 3. ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ í†µí•©
        normalized = re.sub(r'\s+', ' ', normalized)
        
        # 4. ì•ë’¤ ê³µë°± ì œê±°
        normalized = normalized.strip()
        
        return normalized
    
    def _is_exact_match(self, user_input: str, itemno: str) -> bool:
        """
        ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì •í™•í•œ ITEMNO ë§¤ì¹­ ì—¬ë¶€ í™•ì¸
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
            itemno: ë§¤ì¹­ëœ ITEMNO
            
        Returns:
            ì •í™•í•œ ë§¤ì¹­ ì—¬ë¶€
        """
        # ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ìœ¼ë¡œ ì •í™•í•œ ë§¤ì¹­ í™•ì¸
        for pattern in self.itemno_patterns:
            match = re.search(pattern, user_input)
            if match and match.group(0) == itemno:
                return True
        
        return False

    def _extract_status_and_priority_with_llm(self, user_input: str) -> Tuple[Optional[str], Optional[str]]:
        """
        ì‹œë‚˜ë¦¬ì˜¤ 2ìš© LLM ê¸°ë°˜ í˜„ìƒì½”ë“œì™€ ìš°ì„ ìˆœìœ„ í†µí•© ì¶”ì¶œ
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
            
        Returns:
            (ì¶”ì¶œëœ í˜„ìƒì½”ë“œ, ì¶”ì¶œëœ ìš°ì„ ìˆœìœ„) íŠœí”Œ
        """
        try:
            # LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = f"""
ë‹¤ìŒ ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì„¤ë¹„ í˜„ìƒì½”ë“œì™€ ìš°ì„ ìˆœìœ„ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

**ì‚¬ìš©ì ì…ë ¥**: {user_input}

**ì¶”ì¶œ ëŒ€ìƒ**:
1. í˜„ìƒì½”ë“œ: ì„¤ë¹„ì˜ ìƒíƒœë‚˜ ë¬¸ì œì ì„ ë‚˜íƒ€ë‚´ëŠ” í‘œí˜„
   - ì˜ˆì‹œ: ê³ ì¥, ëˆ„ì„¤, ì‘ë™ë¶ˆëŸ‰, ì†ŒìŒ, ì§„ë™, ì˜¨ë„ìƒìŠ¹, ì••ë ¥ìƒìŠ¹, ì ê²€, ì •ë¹„, ê²°í•¨, ìˆ˜ëª…ì†Œì§„, leak, bolting ë“±

2. ìš°ì„ ìˆœìœ„: ì‘ì—…ì˜ ê¸´ê¸‰ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í‘œí˜„ (ì„ íƒì‚¬í•­)
   - ê¸´ê¸‰ì‘ì—…: "ê¸´ê¸‰", "ê¸´ê¸‰ì‘ì—…", "ìµœìš°ì„ ", "urgent", "emergency", "ì¦‰ì‹œ", "ë°”ë¡œ"
   - ìš°ì„ ì‘ì—…: "ìš°ì„ ", "ìš°ì„ ì‘ì—…", "priority", "high priority", "ë¨¼ì €", "ì¤‘ìš”"
   - ì¼ë°˜ì‘ì—…: "ì¼ë°˜", "ì¼ë°˜ì‘ì—…", "normal", "regular", "ë³´í†µ"
   - ì£¼ê¸°ì‘ì—…: "ì£¼ê¸°", "ì£¼ê¸°ì‘ì—…", "ì •ê¸°", "PM", "TA", "ì ê²€"

**ì¶”ì¶œ ê·œì¹™**:
1. í˜„ìƒì½”ë“œ: ì„¤ë¹„ ìƒíƒœë‚˜ ë¬¸ì œì ì„ ì§ì ‘ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ë‹¨ì–´ë‚˜ êµ¬ë¬¸ ì¶”ì¶œ
2. ìš°ì„ ìˆœìœ„: ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰í•œ ê²½ìš°ì—ë§Œ ì¶”ì¶œ
3. ì—¬ëŸ¬ í˜„ìƒì´ ì–¸ê¸‰ëœ ê²½ìš° ê°€ì¥ ì£¼ìš”í•œ í˜„ìƒ í•˜ë‚˜ë§Œ ì¶”ì¶œ
4. í˜„ìƒ/ìš°ì„ ìˆœìœ„ì™€ ê´€ë ¨ ì—†ëŠ” ë‹¨ì–´ëŠ” ì œì™¸ (ITEMNO, ìœ„ì¹˜, ì‘ì—… ë“±)
5. í•´ë‹¹ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° "None" ë°˜í™˜

**ì‘ë‹µ í˜•ì‹**:
```json
{{
    "status_code": "ì¶”ì¶œëœ í˜„ìƒì½”ë“œ ë˜ëŠ” None",
    "priority": "ì¶”ì¶œëœ ìš°ì„ ìˆœìœ„ ë˜ëŠ” None"
}}
```

**ì˜ˆì‹œ**:
- ì…ë ¥: "44043-CA1-6"-P, Leak ë³¼íŒ… ì‘ì—…" â†’ ì¶œë ¥: {{"status_code": "leak", "priority": "None"}}
- ì…ë ¥: "Y-MV1035. ê³ ì¥" â†’ ì¶œë ¥: {{"status_code": "ê³ ì¥", "priority": "None"}}
- ì…ë ¥: "SW-CV1307-02, ì†ŒìŒ ë°œìƒ, ìš°ì„ ì‘ì—…" â†’ ì¶œë ¥: {{"status_code": "ì†ŒìŒ", "priority": "ìš°ì„ ì‘ì—…"}}
- ì…ë ¥: "44043-CA1-6"-P, ê²°í•¨, ê¸´ê¸‰ì‘ì—…" â†’ ì¶œë ¥: {{"status_code": "ê²°í•¨", "priority": "ê¸´ê¸‰ì‘ì—…"}}
- ì…ë ¥: "PE-SE1304B" â†’ ì¶œë ¥: {{"status_code": "None", "priority": "None"}}
"""
            
            # LLM í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=Config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì„¤ë¹„ê´€ë¦¬ ì‹œìŠ¤í…œì˜ í˜„ìƒì½”ë“œì™€ ìš°ì„ ìˆœìœ„ ì¶”ì¶œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=150
            )
            
            result = response.choices[0].message.content.strip()
            
            # ì‘ë‹µ íŒŒì‹±
            parsed_result = self._parse_status_priority_response(result)
            
            status_code = parsed_result.get("status_code")
            priority = parsed_result.get("priority")
            
            # "None" ë¬¸ìì—´ì„ ì‹¤ì œ Noneìœ¼ë¡œ ë³€í™˜
            if status_code == "None":
                status_code = None
            if priority == "None":
                priority = None
            
            return status_code, priority
            
        except Exception as e:
            print(f"LLM í˜„ìƒì½”ë“œ/ìš°ì„ ìˆœìœ„ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            # í´ë°±: ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
            return self._extract_status_and_priority_fallback(user_input)
    
    def _parse_status_priority_response(self, response_text: str) -> Dict:
        """
        í˜„ìƒì½”ë“œ/ìš°ì„ ìˆœìœ„ ì¶”ì¶œ ì‘ë‹µ íŒŒì‹±
        
        Args:
            response_text: LLM ì‘ë‹µ í…ìŠ¤íŠ¸
            
        Returns:
            íŒŒì‹±ëœ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # JSON ë¶€ë¶„ ì¶”ì¶œ
            json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group(1))
            else:
                # JSON ë¸”ë¡ì´ ì—†ëŠ” ê²½ìš° ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ JSONìœ¼ë¡œ íŒŒì‹± ì‹œë„
                data = json.loads(response_text)
            
            return data
            
        except Exception as e:
            print(f"í˜„ìƒì½”ë“œ/ìš°ì„ ìˆœìœ„ ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return {"status_code": "None", "priority": "None"}
    
    def _extract_status_and_priority_fallback(self, user_input: str) -> Tuple[Optional[str], Optional[str]]:
        """
        LLM ì‹¤íŒ¨ ì‹œ í´ë°±ìš© í˜„ìƒì½”ë“œ/ìš°ì„ ìˆœìœ„ ì¶”ì¶œ
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
            
        Returns:
            (ì¶”ì¶œëœ í˜„ìƒì½”ë“œ, ì¶”ì¶œëœ ìš°ì„ ìˆœìœ„) íŠœí”Œ
        """
        # í˜„ìƒì½”ë“œ ì¶”ì¶œ
        status_keywords = [
            'ê³ ì¥', 'ëˆ„ì„¤', 'ì‘ë™ë¶ˆëŸ‰', 'ì†ŒìŒ', 'ì§„ë™', 'ì˜¨ë„ìƒìŠ¹', 'ì••ë ¥ìƒìŠ¹', 
            'ì ê²€', 'ì •ë¹„', 'ê²°í•¨', 'ìˆ˜ëª…ì†Œì§„', 'leak', 'bolting'
        ]
        
        status_code = None
        for keyword in status_keywords:
            if keyword.lower() in user_input.lower():
                status_code = keyword
                break
        
        # ìš°ì„ ìˆœìœ„ ì¶”ì¶œ
        priority = None
        for priority_type, keywords in self.priority_keywords.items():
            for keyword in keywords:
                if keyword.lower() in user_input.lower():
                    priority = priority_type
                    break
            if priority:
                break
        
        return status_code, priority

    def _extract_status_code_with_llm(self, user_input: str) -> Optional[str]:
        """
        ì‹œë‚˜ë¦¬ì˜¤ 2ìš© LLM ê¸°ë°˜ í˜„ìƒì½”ë“œ ì¶”ì¶œ (ê¸°ì¡´ ë©”ì„œë“œ ìœ ì§€ - í˜¸í™˜ì„±)
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
            
        Returns:
            ì¶”ì¶œëœ í˜„ìƒì½”ë“œ ë˜ëŠ” None
        """
        # í†µí•© ë©”ì„œë“œ í˜¸ì¶œ
        status_code, _ = self._extract_status_and_priority_with_llm(user_input)
        return status_code

    def _calculate_scenario_2_confidence(self, user_input: str, itemno: str, status_code: str, priority: str) -> float:
        """
        ì‹œë‚˜ë¦¬ì˜¤ 2ìš© ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥
            itemno: ì¶”ì¶œëœ ITEMNO
            status_code: ì¶”ì¶œëœ í˜„ìƒì½”ë“œ
            priority: ì¶”ì¶œëœ ìš°ì„ ìˆœìœ„
            
        Returns:
            ì‹ ë¢°ë„ ì ìˆ˜ (0.0 ~ 1.0)
        """
        confidence = 0.0
        
        # ITEMNO ì¡´ì¬ ì—¬ë¶€ (ê¸°ë³¸ ì ìˆ˜)
        if itemno:
            if self._is_exact_match(user_input, itemno):
                confidence += 0.5  # ì •í™•í•œ ë§¤ì¹­
            else:
                confidence += 0.3  # ìœ ì‚¬ë„ ë§¤ì¹­
        
        # í˜„ìƒì½”ë“œ ì¡´ì¬ ì—¬ë¶€
        if status_code:
            confidence += 0.3
        
        # ìš°ì„ ìˆœìœ„ ì¡´ì¬ ì—¬ë¶€ (ë³´ë„ˆìŠ¤)
        if priority:
            confidence += 0.1
        
        # ì…ë ¥ ë³µì¡ë„ ê³ ë ¤
        if ',' in user_input:  # ì—¬ëŸ¬ ì •ë³´ê°€ í¬í•¨ëœ ê²½ìš°
            confidence += 0.1
        
        return min(1.0, confidence)

    def _parse_default_scenario(self, user_input: str) -> ParsedInput:
        """
        ê¸°ë³¸ ì‹œë‚˜ë¦¬ì˜¤ íŒŒì‹±
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
            
        Returns:
            ParsedInput: ê¸°ë³¸ íŒŒì‹± ê²°ê³¼
        """
        return ParsedInput(
            scenario="default",
            location=None,
            equipment_type=None,
            status_code=None,
            priority=None,
            itemno=None,
            confidence=0.3
        )

# ì „ì—­ ì…ë ¥ íŒŒì„œ ì¸ìŠ¤í„´ìŠ¤
# ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ importí•˜ì—¬ ì‚¬ìš©
input_parser = InputParser() 