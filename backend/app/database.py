"""
PMark3 ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ ëª¨ë“ˆ

=== ëª¨ë“ˆ ê°œìš” ===
SQLite ë°ì´í„°ë² ì´ìŠ¤ì™€ì˜ ëª¨ë“  ìƒí˜¸ì‘ìš©ì„ ë‹´ë‹¹í•˜ëŠ” í•µì‹¬ ëª¨ë“ˆì…ë‹ˆë‹¤.
ìœ„ì¹˜ ê¸°ë°˜ ìš°ì„  ê²€ìƒ‰, ì •ê·œí™” ì—”ì§„ ì—°ë™, ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œì„ ì§€ì›í•©ë‹ˆë‹¤.

=== Production ì „í™˜ ì£¼ìš” í¬ì¸íŠ¸ ===
ğŸ”„ Azure SQL Database: SQLite â†’ Azure SQL Database ë§ˆì´ê·¸ë ˆì´ì…˜
ğŸš€ ì—°ê²° í’€ë§: ë™ì‹œ ì ‘ì† ìµœì í™” ë° íŠ¸ëœì­ì…˜ ê´€ë¦¬
ğŸ“Š ì¿¼ë¦¬ ìµœì í™”: ì¸ë±ìŠ¤ íŒíŠ¸, ì‹¤í–‰ ê³„íš ë¶„ì„
ğŸ” ë²¡í„° ê²€ìƒ‰ í†µí•©: ê¸°ì¡´ í‚¤ì›Œë“œ ê²€ìƒ‰ + ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰

=== í˜„ì¬ vs Production ë¹„êµ ===
ğŸ“‹ í˜„ì¬ ë°©ì‹:
- SQLite ë¡œì»¬ DB
- ë‹¨ìˆœ LIKE ì¿¼ë¦¬ ê¸°ë°˜ ê²€ìƒ‰
- ìˆœì°¨ì  ê²€ìƒ‰ (ìœ„ì¹˜ â†’ ì„¤ë¹„ â†’ í˜„ìƒ)
- ì •ê·œí™” ì—”ì§„ ì—°ë™ (ì‚¬í›„ ì²˜ë¦¬)

ğŸš€ Production ë°©ì‹:
- Azure SQL Database (ê³ ê°€ìš©ì„±)
- ìµœì í™”ëœ T-SQL ì¿¼ë¦¬
- ë³‘ë ¬ ê²€ìƒ‰ ë° ì¸ë±ìŠ¤ ìµœì í™”
- ë²¡í„° DB í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰

=== ìœ„ì¹˜ ê¸°ë°˜ ê²€ìƒ‰ êµ¬í˜„ ===
ğŸ¯ í˜„ì¬ ê²€ì¦ëœ ê¸°ëŠ¥: 
- search_similar_notifications()ì—ì„œ location/process ìš°ì„  ë§¤ì¹­
- ì •ê·œí™” ì—”ì§„ì„ í†µí•œ ìš©ì–´ í‘œì¤€í™”
- ìœ ì‚¬ë„ ì ìˆ˜ ê¸°ë°˜ ê²°ê³¼ ìˆœìœ„í™”

ğŸ” ê²€ìƒ‰ ì „ëµ:
1. ìœ„ì¹˜ ì •í™• ë§¤ì¹­ (location = ?)
2. ê³µì • ë¶€ë¶„ ë§¤ì¹­ (process LIKE ?)
3. ì„¤ë¹„ìœ í˜• ë§¤ì¹­ (equipType = ?)
4. í˜„ìƒì½”ë“œ ë§¤ì¹­ (statusCode = ?)

=== ì—°ê³„ ì‹œìŠ¤í…œ ===
â¬…ï¸ ì…ë ¥ë‹¨:
- logic/recommender.py: search_similar_notifications() í˜¸ì¶œ
- logic/normalizer.py: _get_db_terms() â†’ í‘œì¤€ ìš©ì–´ ì¶”ì¶œ
- agents/parser.py: ê°„ì ‘ í˜¸ì¶œ (ì •ê·œí™” í†µí•´)

â¡ï¸ ì¶œë ¥ë‹¨:
- models.py: Recommendation ê°ì²´ ìƒì„±ìš© ë°ì´í„° ì œê³µ
- Excel íŒŒì¼: ì´ˆê¸° ë°ì´í„° ë¡œë“œ ë° ë™ê¸°í™”

=== AI ì—°êµ¬ì› ì‹¤í—˜ í¬ì¸íŠ¸ ===
1. ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ ê°œì„ : notebooks/04_database_experiment.ipynb í™œìš©
2. ì¸ë±ì‹± ì „ëµ: ë³µí•© ì¸ë±ìŠ¤ vs ë‹¨ì¼ ì¸ë±ìŠ¤ ì„±ëŠ¥ ë¹„êµ
3. ì¿¼ë¦¬ ìµœì í™”: LIKE vs MATCH vs ë²¡í„° ê²€ìƒ‰ ì„±ëŠ¥ ì¸¡ì •
4. ìºì‹± ì „ëµ: ìì£¼ ê²€ìƒ‰ë˜ëŠ” íŒ¨í„´ ì‚¬ì „ ìºì‹±

=== ê°œë°œíŒ€ êµ¬í˜„ ê°€ì´ë“œ ===
ğŸ—ï¸ Azure SQL ë§ˆì´ê·¸ë ˆì´ì…˜:
```python
class AzureDatabaseManager(DatabaseInterface):
    def __init__(self, connection_string):
        self.engine = create_engine(
            connection_string,
            pool_size=20,
            max_overflow=0,
            pool_pre_ping=True
        )
    
    def search_similar_notifications(self, **kwargs):
        # T-SQL ìµœì í™” ì¿¼ë¦¬
        query = text('''
            SELECT *, 
            (CASE WHEN location = :location THEN 35 ELSE 0 END +
             CASE WHEN equipType = :equipment THEN 35 ELSE 0 END +
             CASE WHEN statusCode = :status THEN 20 ELSE 0 END) / 90.0 as similarity_score
            FROM notification_history 
            WHERE location = :location OR process LIKE :location
            ORDER BY similarity_score DESC, created_at DESC
        ''')
```

ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§:
- ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„ (ëª©í‘œ: <100ms)
- ì—°ê²° í’€ ì‚¬ìš©ë¥  (ëª©í‘œ: <80%)
- ì¸ë±ìŠ¤ íˆíŠ¸ìœ¨ (ëª©í‘œ: >95%)
- ë°ì´í„° ì¦ê°€ìœ¨ ì¶”ì 
"""

import sqlite3
import pandas as pd
import os
from typing import List, Dict, Any, Optional
from .config import Config
from .logic.normalizer import normalizer
import logging

class DatabaseManager:
    """
    ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ í•µì‹¬ í´ë˜ìŠ¤ (í˜„ì¬ í”„ë¡œí† íƒ€ì…)
    
    === í˜„ì¬ ì•„í‚¤í…ì²˜ì—ì„œì˜ ì—­í•  ===
    ğŸ¯ ìœ„ì¹˜ ìš°ì„  ê²€ìƒ‰: location/process ê¸°ë°˜ ìš°ì„  ë§¤ì¹­ êµ¬í˜„
    ğŸ” ìœ ì‚¬ë„ ê³„ì‚°: ë‹¤ì¤‘ í•„ë“œ ë§¤ì¹­ì„ í†µí•œ ê²€ìƒ‰ ê²°ê³¼ ìˆœìœ„í™”
    ğŸ“Š ì •ê·œí™” ì—°ë™: LLM ì •ê·œí™” ì—”ì§„ê³¼ í˜‘ë ¥í•˜ì—¬ í‘œì¤€ ìš©ì–´ ë§¤ì¹­
    ğŸ¤ Excel ì—°ë™: ì´ˆê¸° ë°ì´í„° ë¡œë“œ ë° ë™ê¸°í™” ì§€ì›
    
    === Production ì „í™˜ ì‹œ ë³€ê²½ì‚¬í•­ ===
    ğŸ”„ LangGraph ë…¸ë“œí™”:
    - search_similar_notifications() â†’ database_search_node()
    - ë¹„ë™ê¸° ì²˜ë¦¬ ì§€ì› ë° ë°°ì¹˜ ì¿¼ë¦¬
    - ìƒíƒœ ê´€ë¦¬ ë° ì—ëŸ¬ ë³µêµ¬
    
    ğŸ—ï¸ Azure SQL Database ì—°ë™:
    ```python
    # í˜„ì¬: SQLite ë™ê¸° ì²˜ë¦¬
    self.conn = sqlite3.connect(self.db_path)
    cursor = self.conn.execute(query, params)
    
    # Production: Azure SQL ë¹„ë™ê¸° ì²˜ë¦¬
    async with self.pool.acquire() as conn:
        async with conn.execute(query, params) as cursor:
            results = await cursor.fetchall()
    ```
    
    ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”:
    - ì—°ê²° í’€ë§: SQLAlchemy ì—”ì§„ í™œìš©
    - ì¿¼ë¦¬ ìºì‹±: Redis ê¸°ë°˜ ê²°ê³¼ ìºì‹±
    - ì¸ë±ìŠ¤ ìµœì í™”: ë³µí•© ì¸ë±ìŠ¤ ë° ì‹¤í–‰ ê³„íš ë¶„ì„
    
    === ìœ„ì¹˜ ê¸°ë°˜ ê²€ìƒ‰ ìƒì„¸ êµ¬í˜„ ===
    ğŸ¯ ê²€ìƒ‰ ìš°ì„ ìˆœìœ„ (í˜„ì¬ êµ¬í˜„ë¨):
    1. ìœ„ì¹˜ ì •í™• ë§¤ì¹­: WHERE location = ?
    2. ê³µì • ë¶€ë¶„ ë§¤ì¹­: WHERE process LIKE ?%
    3. ì„¤ë¹„ìœ í˜• ë§¤ì¹­: WHERE equipType = ?
    4. í˜„ìƒì½”ë“œ ë§¤ì¹­: WHERE statusCode = ?
    
    ğŸ’¡ ê²€ìƒ‰ ì „ëµ:
    - ì •ê·œí™” ì „ì²˜ë¦¬: ì…ë ¥ê°’ â†’ í‘œì¤€ ìš©ì–´ ë³€í™˜
    - ë‹¨ê³„ë³„ ê²€ìƒ‰: ìœ„ì¹˜ â†’ ì„¤ë¹„ â†’ í˜„ìƒ ìˆœì„œ
    - ìœ ì‚¬ë„ ì ìˆ˜: ë§¤ì¹­ í•„ë“œ ìˆ˜ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ì ìš©
    
    === ì—°ê³„ ì§€ì  ìƒì„¸ ë¶„ì„ ===
    â¬…ï¸ í˜¸ì¶œí•˜ëŠ” ëª¨ë“ˆ:
    - logic/recommender.py.get_recommendations() â†’ search_similar_notifications()
    - logic/normalizer.py._get_db_terms() â†’ í‘œì¤€ ìš©ì–´ ë™ì  ë¡œë“œ
    - api/chat.py â†’ ì§ì ‘ ë°ì´í„° ê²€ì¦ í˜¸ì¶œ
    
    â¡ï¸ í˜¸ì¶œë˜ëŠ” ëª¨ë“ˆ:
    - logic/normalizer.py.normalize_term() â†’ ê²€ìƒ‰ ì „ ìš©ì–´ ì •ê·œí™”
    - config.py â†’ ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ ë° ì„¤ì • ì°¸ì¡°
    - Excel íŒŒì¼ â†’ ì´ˆê¸° ë°ì´í„° ì†ŒìŠ¤
    
    === AI ì—°êµ¬ì› ì‹¤í—˜ ê°€ì´ë“œ ===
    ğŸ“ ê²€ìƒ‰ ì„±ëŠ¥ ê°œì„ :
    - notebooks/04_database_experiment.ipynb í™œìš©
    - ì¿¼ë¦¬ íŒ¨í„´ ë¶„ì„ ë° ìµœì í™”
    - ì¸ë±ìŠ¤ íš¨ê³¼ ì¸¡ì • ë° íŠœë‹
    
    ğŸ”¬ ê²€ìƒ‰ ì •í™•ë„ í‰ê°€:
    - ìœ„ì¹˜ ê¸°ë°˜ ê²€ìƒ‰ ì •í™•ë„ ì¸¡ì •
    - ì‚¬ìš©ì ì˜ë„ vs ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„
    - False Positive/Negative ì¼€ì´ìŠ¤ ë¶„ì„
    
    === ê°œë°œíŒ€ êµ¬í˜„ ì°¸ê³  ===
    ğŸ—ï¸ Production êµ¬í˜„ í¬ì¸íŠ¸:
    - ë°ì´í„°ë² ì´ìŠ¤ ì¶”ìƒí™” ë ˆì´ì–´ êµ¬í˜„
    - íŠ¸ëœì­ì…˜ ê´€ë¦¬ ë° ë¡¤ë°± ë©”ì»¤ë‹ˆì¦˜
    - ì—°ê²° ìƒíƒœ ëª¨ë‹ˆí„°ë§ ë° ìë™ ë³µêµ¬
    
    ğŸ“Š ëª¨ë‹ˆí„°ë§ ì§€í‘œ:
    - ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„ ë¶„í¬
    - ê²€ìƒ‰ ê²°ê³¼ ì •í™•ë„ (ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜)
    - ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì•ˆì •ì„±
    - ì¸ë±ìŠ¤ í™œìš©ë¥  ë° í…Œì´ë¸” ìŠ¤ìº” ë¹„ìœ¨
    
    ğŸ¯ í™•ì¥ì„± ê³ ë ¤ì‚¬í•­:
    - ìƒ¤ë”© ì „ëµ (ë°ì´í„° ë¶„ì‚°)
    - ì½ê¸° ë³µì œë³¸ í™œìš© (ì½ê¸° ì„±ëŠ¥ í–¥ìƒ)
    - ë°ì´í„° ì•„ì¹´ì´ë¹™ ì •ì±… (ì˜¤ë˜ëœ ë°ì´í„° ê´€ë¦¬)
    """
    
    def __init__(self):
        """
        ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        
        ì„¤ì •:
        - ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •
        - í…Œì´ë¸” ìƒì„± (ì—†ëŠ” ê²½ìš°)
        - ë¡œê¹… ì„¤ì •
        """
        self.db_path = Config.SQLITE_DB_PATH
        self.conn = None
        self.logger = logging.getLogger(__name__)
        self._ensure_data_directory()
        self._initialize_database()
    
    def _ensure_data_directory(self):
        """ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±"""
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
    
    def _initialize_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ë° í…Œì´ë¸” ìƒì„±"""
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.logger.info(f"DB íŒŒì¼ ê²½ë¡œ: {self.db_path}, ì¡´ì¬ ì—¬ë¶€: {os.path.exists(self.db_path)}")
        
        # ì‘ì—…ìš”ì²­ ì´ë ¥ í…Œì´ë¸” ìƒì„±
        self.conn.execute('''
            CREATE TABLE IF NOT EXISTS notification_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                itemno TEXT NOT NULL,
                process TEXT,
                location TEXT,
                equipType TEXT,
                statusCode TEXT,
                work_title TEXT,
                work_details TEXT,
                priority TEXT DEFAULT 'ì¼ë°˜ì‘ì—…',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # í˜„ìƒì½”ë“œ í…Œì´ë¸” ìƒì„±
        self.conn.execute('''
            CREATE TABLE IF NOT EXISTS status_codes (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                code TEXT NOT NULL,
                description TEXT,
                category TEXT
            )
        ''')
        
        # ì„¤ë¹„ìœ í˜• í…Œì´ë¸” ìƒì„±
        self.conn.execute('''
            CREATE TABLE IF NOT EXISTS equipment_types (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                type_code TEXT NOT NULL,
                type_name TEXT,
                category TEXT
            )
        ''')
        
        # ì¸ë±ìŠ¤ ìƒì„± (ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒ)
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_equipType ON notification_history(equipType)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_location ON notification_history(location)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_statusCode ON notification_history(statusCode)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_process ON notification_history(process)")
        
        self.conn.commit()
        self.logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def load_excel_data(self):
        """Excel íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ"""
        try:
            # íŒŒì¼ ê²½ë¡œë¥¼ ì ˆëŒ€ê²½ë¡œë¡œ ë³€í™˜
            notification_file = os.path.abspath(Config.NOTIFICATION_HISTORY_FILE)
            status_file = os.path.abspath(Config.STATUS_CODE_FILE)
            equipment_file = os.path.abspath(Config.EQUIPMENT_TYPE_FILE)
            
            # íŒŒì¼ ê²½ë¡œ ë¡œê¹…
            self.logger.info(f"ì—‘ì…€ íŒŒì¼ ê²½ë¡œ í™•ì¸:")
            self.logger.info(f"  - ì‘ì—…ìš”ì²­ ì´ë ¥: {notification_file} (ì¡´ì¬: {os.path.exists(notification_file)})")
            self.logger.info(f"  - í˜„ìƒì½”ë“œ: {status_file} (ì¡´ì¬: {os.path.exists(status_file)})")
            self.logger.info(f"  - ì„¤ë¹„ìœ í˜•: {equipment_file} (ì¡´ì¬: {os.path.exists(equipment_file)})")

            # ì‘ì—…ìš”ì²­ ì´ë ¥ ë¡œë“œ
            if os.path.exists(notification_file):
                df_history = pd.read_excel(notification_file)
                # ì»¬ëŸ¼ëª… strip ì²˜ë¦¬
                df_history.columns = [c.strip() for c in df_history.columns]
                self.logger.info(f"ì‘ì—…ìš”ì²­ ì´ë ¥ íŒŒì¼ ë¡œë“œ: {len(df_history)} ê±´, ì»¬ëŸ¼: {df_history.columns.tolist()}")
                
                # ì»¬ëŸ¼ëª… ë§¤í•‘ (ì‹¤ì œ Excel íŒŒì¼ êµ¬ì¡°ì— ë§ì¶¤)
                column_mapping = {
                    'ì‘ì—…ëŒ€ìƒ': 'itemno',
                    'Plant': 'process', 
                    'Location': 'location',
                    'ì„¤ë¹„ìœ í˜•': 'equipType',
                    'í˜„ìƒì½”ë“œ': 'statusCode',  # ì‹¤ì œ ì»¬ëŸ¼ëª…ì— ë§ì¶¤ (ê³µë°± ì—†ìŒ)
                    'ì‘ì—…ëª…': 'work_title',
                    'ìš°ì„  ìˆœìœ„': 'priority'
                }
                df_history = df_history.rename(columns=column_mapping)
                self.logger.info(f"ì»¬ëŸ¼ëª… ë§¤í•‘ í›„: {df_history.columns.tolist()}")
                required_columns = ['itemno', 'process', 'location', 'equipType', 'statusCode', 'work_title', 'priority']
                for col in required_columns:
                    if col not in df_history.columns:
                        self.logger.error(f"ì‘ì—…ìš”ì²­ ì´ë ¥ íŒŒì¼ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {col}")
                        raise RuntimeError(f"ì‘ì—…ìš”ì²­ ì´ë ¥ íŒŒì¼ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {col}")
                df_history['work_details'] = df_history.get('work_title', '')
                df_history['created_at'] = pd.Timestamp.now()
                df_history = df_history[required_columns + ['work_details', 'created_at']]
                df_history.to_sql('notification_history', self.conn, if_exists='replace', index=False)
                self.conn.commit()
                self.logger.info(f"ì‘ì—…ìš”ì²­ ì´ë ¥ ë¡œë“œ ì™„ë£Œ: {len(df_history)} ê±´")
            else:
                self.logger.error(f"ì‘ì—…ìš”ì²­ ì´ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {notification_file}")
                raise RuntimeError(f"ì‘ì—…ìš”ì²­ ì´ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {notification_file}")
            
            # í˜„ìƒì½”ë“œ ë¡œë“œ
            if os.path.exists(status_file):
                df_status = pd.read_excel(status_file)
                df_status.columns = [c.strip() for c in df_status.columns]
                self.logger.info(f"í˜„ìƒì½”ë“œ íŒŒì¼ ë¡œë“œ: {len(df_status)} ê±´, ì»¬ëŸ¼: {df_status.columns.tolist()}")
                if 'í˜„ìƒì½”ë“œ' in df_status.columns:
                    df_status = df_status[['í˜„ìƒì½”ë“œ']].copy()
                    df_status.columns = ['code']
                    df_status['description'] = df_status['code']
                    df_status['category'] = 'ì¼ë°˜'
                df_status.to_sql('status_codes', self.conn, if_exists='replace', index=False)
                self.conn.commit()
                self.logger.info(f"í˜„ìƒì½”ë“œ ë¡œë“œ ì™„ë£Œ: {len(df_status)} ê±´")
            else:
                self.logger.error(f"í˜„ìƒì½”ë“œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {status_file}")
                raise RuntimeError(f"í˜„ìƒì½”ë“œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {status_file}")
            
            # ì„¤ë¹„ìœ í˜• ë¡œë“œ (ë‘ ë²ˆì§¸ ì‹œíŠ¸ ì‚¬ìš©)
            if os.path.exists(equipment_file):
                # ë‘ ë²ˆì§¸ ì‹œíŠ¸ 'ì„¤ë¹„ìœ í˜•' ì½ê¸°
                df_equip = pd.read_excel(equipment_file, sheet_name='ì„¤ë¹„ìœ í˜•')
                df_equip.columns = [c.strip() for c in df_equip.columns]
                self.logger.info(f"ì„¤ë¹„ìœ í˜• íŒŒì¼ ë¡œë“œ (ë‘ ë²ˆì§¸ ì‹œíŠ¸): {len(df_equip)} ê±´, ì»¬ëŸ¼: {df_equip.columns.tolist()}")
                
                if len(df_equip.columns) >= 4:
                    # í—¤ë” ì œê±° (ì²« ë²ˆì§¸ í–‰ì´ í—¤ë”)
                    if df_equip.iloc[0, 1] == 'ì„¤ë¹„ìœ í˜• ëŒ€ë¶„ë¥˜':
                        df_equip = df_equip.iloc[1:].reset_index(drop=True)
                    
                    # ì»¬ëŸ¼ëª… ë§¤í•‘ ìˆ˜ì •: Dì»¬ëŸ¼(4ë²ˆì§¸)ì„ type_nameìœ¼ë¡œ ì‚¬ìš©
                    # A: id, B: category, C: temp, D: type_name (Dì»¬ëŸ¼ ì „ì²´ ê°’)
                    df_equip.columns = ['id', 'category', 'temp', 'type_name']
                    # type_name(Dì»¬ëŸ¼)ì„ type_codeë¡œë„ ì‚¬ìš©í•˜ì—¬ Dì»¬ëŸ¼ ì „ì²´ ê°’ì´ ë°˜í™˜ë˜ë„ë¡ í•¨
                    df_equip['type_code'] = df_equip['type_name']
                    df_equip = df_equip[['type_code', 'type_name', 'category']].copy()
                    
                    # ë¹ˆ ê°’ ì œê±°
                    df_equip = df_equip.dropna(subset=['type_code', 'type_name'])
                    
                    df_equip.to_sql('equipment_types', self.conn, if_exists='replace', index=False)
                    self.conn.commit()
                    self.logger.info(f"ì„¤ë¹„ìœ í˜• ë¡œë“œ ì™„ë£Œ: {len(df_equip)} ê±´")
                else:
                    self.logger.error("ì„¤ë¹„ìœ í˜• íŒŒì¼ì˜ ì»¬ëŸ¼ êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤.")
                    raise RuntimeError("ì„¤ë¹„ìœ í˜• íŒŒì¼ì˜ ì»¬ëŸ¼ êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤.")
            else:
                self.logger.error(f"ì„¤ë¹„ìœ í˜• íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {equipment_file}")
                raise RuntimeError(f"ì„¤ë¹„ìœ í˜• íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {equipment_file}")
            
        except Exception as e:
            self.logger.error(f"Excel ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            raise
    
    def _create_sample_data(self):
        """ìƒ˜í”Œ ë°ì´í„° ìƒì„± (Excel íŒŒì¼ì´ ì—†ì„ ê²½ìš°)"""
        # ìƒ˜í”Œ ì‘ì—…ìš”ì²­ ì´ë ¥
        sample_history = [
            ("44043-CA1-6\"-P", "RFCC", "No.1 PE", "Pressure Vessel", "ê³ ì¥", "ì••ë ¥ìš©ê¸° ëˆ„ì„¤ ì ê²€", "ì••ë ¥ìš©ê¸° ì—°ê²°ë¶€ìœ„ ëˆ„ì„¤ í™•ì¸ ë° ìˆ˜ë¦¬", "ì¼ë°˜ì‘ì—…"),
            ("Y-MV1035", "ì„ìœ ì œí’ˆë°°í•©/ì €ì¥", "Motor Operated Valve", "Motor Operated Valve", "ì‘ë™ë¶ˆëŸ‰", "ëª¨í„°ë°¸ë¸Œ ì‘ë™ë¶ˆëŸ‰ ì ê²€", "ëª¨í„°ë°¸ë¸Œ ì‘ë™ìƒíƒœ í™•ì¸ ë° ìˆ˜ë¦¬", "ê¸´ê¸‰ì‘ì—…"),
            ("SW-CV1307-02", "í•©ì„±ìˆ˜ì§€ í¬ì¥", "1ì°½ê³  #7Line", "Conveyor", "ê³ ì¥", "ì»¨ë² ì´ì–´ ëŸ¬ë²„ë²¨íŠ¸ êµì²´", "ì»¨ë² ì´ì–´ ëŸ¬ë²„ë²¨íŠ¸ ë§ˆëª¨ í™•ì¸ ë° êµì²´", "ìš°ì„ ì‘ì—…"),
            ("RFCC-001", "RFCC", "No.1 PE", "Heat Exchanger", "ëˆ„ì„¤", "ì—´êµí™˜ê¸° ëˆ„ì„¤ ì ê²€", "ì—´êµí™˜ê¸° íŠœë¸Œ ëˆ„ì„¤ í™•ì¸ ë° ìˆ˜ë¦¬", "ì¼ë°˜ì‘ì—…"),
            ("MV-2024-001", "ì„ìœ ì œí’ˆë°°í•©/ì €ì¥", "Storage Tank", "Valve", "ê³ ì¥", "ì €ì¥íƒ±í¬ ë°¸ë¸Œ êµì²´", "ì €ì¥íƒ±í¬ ì¶œêµ¬ ë°¸ë¸Œ êµì²´", "ê¸´ê¸‰ì‘ì—…")
        ]
        
        for itemno, process, location, equipType, statusCode, work_title, work_details, priority in sample_history:
            self.conn.execute('''
                INSERT INTO notification_history 
                (itemno, process, location, equipType, statusCode, work_title, work_details, priority, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
            ''', (itemno, process, location, equipType, statusCode, work_title, work_details, priority))
        
        # ìƒ˜í”Œ í˜„ìƒì½”ë“œ
        sample_status_codes = [
            ("ê³ ì¥", "ì„¤ë¹„ ê³ ì¥", "ì„¤ë¹„"),
            ("ëˆ„ì„¤", "ìœ ì²´ ëˆ„ì„¤", "ëˆ„ì„¤"),
            ("ì‘ë™ë¶ˆëŸ‰", "ì •ìƒ ì‘ë™í•˜ì§€ ì•ŠìŒ", "ì‘ë™"),
            ("ì†ŒìŒ", "ë¹„ì •ìƒ ì†ŒìŒ ë°œìƒ", "ì†ŒìŒ"),
            ("ì§„ë™", "ê³¼ë„í•œ ì§„ë™", "ì§„ë™"),
            ("ì˜¨ë„ìƒìŠ¹", "ë¹„ì •ìƒ ì˜¨ë„ ìƒìŠ¹", "ì˜¨ë„"),
            ("ì••ë ¥ìƒìŠ¹", "ë¹„ì •ìƒ ì••ë ¥ ìƒìŠ¹", "ì••ë ¥")
        ]
        
        for code, description, category in sample_status_codes:
            self.conn.execute('''
                INSERT INTO status_codes (code, description, category)
                VALUES (?, ?, ?)
            ''', (code, description, category))
        
        # ìƒ˜í”Œ ì„¤ë¹„ìœ í˜•
        sample_equipment_types = [
            ("PV", "Pressure Vessel", "ìš©ê¸°"),
            ("HE", "Heat Exchanger", "ì—´êµí™˜ê¸°"),
            ("MV", "Motor Operated Valve", "ë°¸ë¸Œ"),
            ("CV", "Control Valve", "ì œì–´ë°¸ë¸Œ"),
            ("PU", "Pump", "íŒí”„"),
            ("CO", "Conveyor", "ì»¨ë² ì´ì–´"),
            ("DR", "Drum", "ë“œëŸ¼"),
            ("TK", "Tank", "íƒ±í¬")
        ]
        
        for type_code, type_name, category in sample_equipment_types:
            self.conn.execute('''
                INSERT INTO equipment_types (type_code, type_name, category)
                VALUES (?, ?, ?)
            ''', (type_code, type_name, category))
        
        self.conn.commit()
        self.logger.info("ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ")
    
    def search_similar_notifications(self, equip_type: str = None, location: str = None, 
                                   status_code: str = None, priority: str = None, limit: int = 15) -> List[Dict[str, Any]]:
        """ìœ ì‚¬í•œ ì‘ì—…ìš”ì²­ ì´ë ¥ ê²€ìƒ‰ (ìœ„ì¹˜ ê¸°ë°˜ ê²€ìƒ‰ ê°•í™” + SQL ì—ëŸ¬ ì²˜ë¦¬)"""
        
        max_retries = 5
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                # ì…ë ¥ê°’ ì •ê·œí™” (ìœ„ì¹˜ ìš°ì„  ì •ê·œí™”)
                normalized_location = self.normalize_term(location, "location") if location else None
                normalized_equip_type = self.normalize_term(equip_type, "equipment") if equip_type else None
                normalized_status_code = self.normalize_term(status_code, "status") if status_code else None
                normalized_priority = self.normalize_term(priority, "priority") if priority else None
                
                query = '''
                    SELECT itemno, process, location, equipType, statusCode, work_title, work_details, priority
                    FROM notification_history
                    WHERE 1=1
                '''
                params = []
                
                # ìœ„ì¹˜ ê¸°ë°˜ ê²€ìƒ‰ ê°•í™” (ìœ„ì¹˜ê°€ ì…ë ¥ëœ ê²½ìš° ìš°ì„  ê²€ìƒ‰)
                if normalized_location:
                    # ìœ„ì¹˜ì™€ ê³µì •ëª… ëª¨ë‘ì—ì„œ ê²€ìƒ‰í•˜ë˜, ìœ„ì¹˜ ë§¤ì¹­ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
                    query += " AND (location LIKE ? OR process LIKE ?)"
                    params.extend([f"%{normalized_location}%", f"%{normalized_location}%"])
                
                if normalized_equip_type:
                    query += " AND equipType LIKE ?"
                    params.append(f"%{normalized_equip_type}%")
                
                if normalized_status_code:
                    query += " AND statusCode LIKE ?"
                    params.append(f"%{normalized_status_code}%")
                
                # ìš°ì„ ìˆœìœ„ëŠ” ì„ íƒì  ê²€ìƒ‰ ì¡°ê±´
                if normalized_priority:
                    query += " AND priority LIKE ?"
                    params.append(f"%{normalized_priority}%")
                
                # ìœ„ì¹˜ê°€ ì…ë ¥ëœ ê²½ìš° ìœ„ì¹˜ ê¸°ë°˜ ì •ë ¬ ìš°ì„ 
                if normalized_location:
                    query += " ORDER BY CASE WHEN location LIKE ? THEN 1 ELSE 2 END, created_at DESC LIMIT ?"
                    params.extend([f"%{normalized_location}%", limit])
                else:
                    query += " ORDER BY created_at DESC LIMIT ?"
                    params.append(limit)
                
                cursor = self.conn.execute(query, params)
                columns = [description[0] for description in cursor.description]
                
                results = []
                for row in cursor.fetchall():
                    result = dict(zip(columns, row))
                    # ì‹¤ì œ ìœ ì‚¬ë„ ì ìˆ˜ëŠ” ì¶”ì²œ ì—”ì§„ì—ì„œ ê³„ì‚°ë˜ë¯€ë¡œ ì„ì‹œ ì ìˆ˜ ì œê±°
                    results.append(result)
                
                # ê²°ê³¼ ìˆ˜ì— ë”°ë¥¸ ì²˜ë¦¬
                if len(results) == 0:
                    self.logger.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ê²€ìƒ‰ìœ¼ë¡œ fallback")
                    return self._fallback_search(limit)
                elif 1 <= len(results) <= 5:
                    self.logger.info(f"ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê±´ (1-5ê±´ ë²”ìœ„)")
                    return results
                elif 6 <= len(results) <= 15:
                    self.logger.info(f"ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê±´ (6-15ê±´ ë²”ìœ„)")
                    return results[:5]  # 5ê°œì”© ë¬¶ì–´ì„œ ë°˜í™˜
                else:
                    self.logger.info(f"ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê±´ (15ê±´ ì´ˆê³¼)")
                    return results[:5]  # ìƒìœ„ 5ê°œë§Œ ë°˜í™˜
                
            except sqlite3.Error as e:
                retry_count += 1
                self.logger.error(f"SQL ì—ëŸ¬ (ì‹œë„ {retry_count}/{max_retries}): {e}")
                
                if retry_count >= max_retries:
                    self.logger.error("ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. ê¸°ë³¸ ê²€ìƒ‰ìœ¼ë¡œ fallback")
                    return self._fallback_search(limit)
                else:
                    # ê°„ë‹¨í•œ ì¿¼ë¦¬ë¡œ ì¬ì‹œë„
                    try:
                        return self._simple_search(limit)
                    except Exception as fallback_error:
                        self.logger.error(f"Fallback ê²€ìƒ‰ë„ ì‹¤íŒ¨: {fallback_error}")
                        return []
        
        return []
    
    def _fallback_search(self, limit: int) -> List[Dict[str, Any]]:
        """ê¸°ë³¸ ê²€ìƒ‰ (SQL ì—ëŸ¬ ì‹œ fallback)"""
        try:
            query = '''
                SELECT itemno, process, location, equipType, statusCode, work_title, work_details, priority
                FROM notification_history
                ORDER BY created_at DESC
                LIMIT ?
            '''
            cursor = self.conn.execute(query, [limit])
            columns = [description[0] for description in cursor.description]
            
            results = []
            for row in cursor.fetchall():
                result = dict(zip(columns, row))
                results.append(result)
            
            return results
        except Exception as e:
            self.logger.error(f"Fallback ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _simple_search(self, limit: int) -> List[Dict[str, Any]]:
        """ê°„ë‹¨í•œ ê²€ìƒ‰ (ë³µì¡í•œ ì¿¼ë¦¬ ì‹¤íŒ¨ ì‹œ)"""
        try:
            query = '''
                SELECT itemno, process, location, equipType, statusCode, work_title, work_details, priority
                FROM notification_history
                LIMIT ?
            '''
            cursor = self.conn.execute(query, [limit])
            columns = [description[0] for description in cursor.description]
            
            results = []
            for row in cursor.fetchall():
                result = dict(zip(columns, row))
                results.append(result)
            
            return results
        except Exception as e:
            self.logger.error(f"ê°„ë‹¨í•œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def normalize_term(self, term: str, category: str) -> str:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ìš©ì–´ë¥¼ í‘œì¤€ ìš©ì–´ë¡œ ì •ê·œí™”"""
        if not term:
            return term
        
        # LLM ì •ê·œí™” ìˆ˜í–‰
        normalized_term, confidence = normalizer.normalize_term(term, category)
        
        # ì‹ ë¢°ë„ê°€ ë‚®ì€ ê²½ìš° ì›ë³¸ ë°˜í™˜ (ì„ê³„ê°’ì„ ë†’ì—¬ì„œ ë” ë³´ìˆ˜ì ìœ¼ë¡œ ì •ê·œí™”)
        if confidence < 0.8:
            return term
        
        return normalized_term
    
    def search_by_itemno(self, itemno: str, limit: int = 15) -> List[Dict[str, Any]]:
        """
        ITEMNOë¡œ ìœ ì‚¬í•œ ì‘ì—…ëŒ€ìƒ ê²€ìƒ‰
        
        Args:
            itemno: ê²€ìƒ‰í•  ì‘ì—…ëŒ€ìƒ ë²ˆí˜¸
            limit: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
            
        Returns:
            ìœ ì‚¬í•œ ì‘ì—…ëŒ€ìƒ ëª©ë¡
            
        ê²€ìƒ‰ ì „ëµ:
        1. ì •í™•í•œ ë§¤ì¹­ ìš°ì„ 
        2. ë¶€ë¶„ ë§¤ì¹­ (í¬í•¨ ê´€ê³„)
        3. ìœ ì‚¬í•œ íŒ¨í„´ ë§¤ì¹­
        """
        # ë‹¤ë‹¨ê³„ ê²€ìƒ‰ ì „ëµ
        results = []
        
        # 1ë‹¨ê³„: ì •í™•í•œ ë§¤ì¹­
        query_exact = '''
            SELECT itemno, process, location, equipType, statusCode, work_title, work_details, priority
            FROM notification_history
            WHERE itemno = ?
            ORDER BY created_at DESC
        '''
        cursor = self.conn.execute(query_exact, [itemno])
        columns = [description[0] for description in cursor.description]
        
        for row in cursor.fetchall():
            result = dict(zip(columns, row))
            results.append(result)
        
        # 2ë‹¨ê³„: ë¶€ë¶„ ë§¤ì¹­ (ì •í™•í•œ ë§¤ì¹­ì´ ì—†ê±°ë‚˜ ë¶€ì¡±í•œ ê²½ìš°)
        if len(results) < limit:
            query_partial = '''
                SELECT itemno, process, location, equipType, statusCode, work_title, work_details, priority
                FROM notification_history
                WHERE itemno LIKE ? AND itemno != ?
                ORDER BY 
                    CASE 
                        WHEN itemno LIKE ? THEN 1  -- ì‹œì‘ ë¶€ë¶„ ë§¤ì¹­
                        WHEN itemno LIKE ? THEN 2  -- ë ë¶€ë¶„ ë§¤ì¹­
                        ELSE 3                     -- ì¤‘ê°„ ë¶€ë¶„ ë§¤ì¹­
                    END,
                    created_at DESC
                LIMIT ?
            '''
            remaining_limit = limit - len(results)
            cursor = self.conn.execute(query_partial, [
                f"%{itemno}%", itemno,  # ë¶€ë¶„ ë§¤ì¹­, ì •í™•í•œ ë§¤ì¹­ ì œì™¸
                f"{itemno}%",           # ì‹œì‘ ë¶€ë¶„ ë§¤ì¹­
                f"%{itemno}",           # ë ë¶€ë¶„ ë§¤ì¹­
                remaining_limit
            ])
            
            for row in cursor.fetchall():
                result = dict(zip(columns, row))
                results.append(result)
        
        # 3ë‹¨ê³„: íŒ¨í„´ ìœ ì‚¬ì„± ê²€ìƒ‰ (ì˜ˆ: ìˆ«ì íŒ¨í„´, ë¬¸ì íŒ¨í„´ ë“±)
        if len(results) < limit:
            # ITEMNO íŒ¨í„´ ë¶„ì„
            import re
            
            # ìˆ«ì íŒ¨í„´ ì¶”ì¶œ
            numbers = re.findall(r'\d+', itemno)
            letters = re.findall(r'[A-Za-z]+', itemno)
            
            if numbers or letters:
                query_pattern = '''
                    SELECT itemno, process, location, equipType, statusCode, work_title, work_details, priority
                    FROM notification_history
                    WHERE itemno NOT LIKE ?
                '''
                params = [f"%{itemno}%"]  # ì´ë¯¸ ê²€ìƒ‰ëœ ë¶€ë¶„ ë§¤ì¹­ ì œì™¸
                
                # ìˆ«ì íŒ¨í„´ ë§¤ì¹­
                if numbers:
                    for num in numbers:
                        query_pattern += " AND itemno LIKE ?"
                        params.append(f"%{num}%")
                
                # ë¬¸ì íŒ¨í„´ ë§¤ì¹­
                if letters:
                    for letter in letters:
                        query_pattern += " AND itemno LIKE ?"
                        params.append(f"%{letter}%")
                
                query_pattern += " ORDER BY created_at DESC LIMIT ?"
                remaining_limit = limit - len(results)
                params.append(remaining_limit)
                
                cursor = self.conn.execute(query_pattern, params)
                
                for row in cursor.fetchall():
                    result = dict(zip(columns, row))
                    results.append(result)
        
        return results[:limit]
    
    def get_status_codes(self) -> List[Dict[str, Any]]:
        """í˜„ìƒì½”ë“œ ëª©ë¡ ì¡°íšŒ"""
        cursor = self.conn.execute("SELECT code, description, category FROM status_codes")
        return [{"code": row[0], "description": row[1], "category": row[2]} for row in cursor.fetchall()]
    
    def get_equipment_types(self) -> List[Dict[str, Any]]:
        """ì„¤ë¹„ìœ í˜• ëª©ë¡ ì¡°íšŒ"""
        cursor = self.conn.execute("SELECT type_code, type_name, category FROM equipment_types")
        return [{"type_code": row[0], "type_name": row[1], "category": row[2]} for row in cursor.fetchall()]
    
    def get_equipment_type_data(self) -> List[Dict[str, Any]]:
        """ì„¤ë¹„ìœ í˜• ìë£Œ ì¡°íšŒ (ìë™ì™„ì„±ìš©)"""
        try:
            cursor = self.conn.execute("SELECT * FROM equipment_types")
            return [dict(zip([col[0] for col in cursor.description], row)) for row in cursor.fetchall()]
        except Exception as e:
            self.logger.error(f"ì„¤ë¹„ìœ í˜• ìë£Œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []
    
    def get_notification_history_data(self) -> List[Dict[str, Any]]:
        """ì‘ì—…ìš”ì²­ ì´ë ¥ ìë£Œ ì¡°íšŒ (ìë™ì™„ì„±ìš©)"""
        try:
            cursor = self.conn.execute("SELECT * FROM notification_history")
            return [dict(zip([col[0] for col in cursor.description], row)) for row in cursor.fetchall()]
        except Exception as e:
            self.logger.error(f"ì‘ì—…ìš”ì²­ ì´ë ¥ ìë£Œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []
    
    def get_notification_by_itemno(self, itemno: str) -> Optional[Dict[str, Any]]:
        """ITEMNOë¡œ íŠ¹ì • ì•Œë¦¼ ì¡°íšŒ"""
        try:
            cursor = self.conn.execute('''
                SELECT itemno, process, location, equipType, statusCode, work_title, work_details, priority
                FROM notification_history
                WHERE itemno = ?
            ''', [itemno])
            
            row = cursor.fetchone()
            if row:
                columns = [description[0] for description in cursor.description]
                return dict(zip(columns, row))
            return None
            
        except Exception as e:
            self.logger.error(f"ITEMNO ì•Œë¦¼ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None
    
    def save_work_order(self, work_order_data: Dict[str, Any]) -> bool:
        """
        ì‘ì—…ìš”ì²­ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        
        Args:
            work_order_data: ì €ì¥í•  ì‘ì—…ìš”ì²­ ë°ì´í„°
            
        Returns:
            ì €ì¥ ì„±ê³µ ì—¬ë¶€
            
        ë‹´ë‹¹ì ìˆ˜ì • ê°€ì´ë“œ:
        - ì™¸ë¶€ ì‹œìŠ¤í…œ ì—°ë™ ë¡œì§ ì¶”ê°€ í•„ìš”
        - íŠ¸ëœì­ì…˜ ì²˜ë¦¬ ë° ë¡¤ë°± ë¡œì§ êµ¬í˜„ í•„ìš”
        - ê°ì‚¬ ë¡œê·¸(Audit Log) ì¶”ê°€ ê¶Œì¥
        """
        try:
            # ì‘ì—…ìš”ì²­ í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±
            self.conn.execute('''
                CREATE TABLE IF NOT EXISTS work_orders (
                    itemno TEXT PRIMARY KEY,
                    work_title TEXT NOT NULL,
                    work_details TEXT NOT NULL,
                    process TEXT,
                    location TEXT,
                    equipType TEXT,
                    statusCode TEXT,
                    priority TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # ì‘ì—…ìš”ì²­ ì €ì¥
            self.conn.execute('''
                INSERT INTO work_orders 
                (itemno, work_title, work_details, process, location, equipType, statusCode, priority, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                work_order_data['itemno'],
                work_order_data['work_title'],
                work_order_data['work_details'],
                work_order_data['process'],
                work_order_data['location'],
                work_order_data['equipType'],
                work_order_data['statusCode'],
                work_order_data['priority'],
                work_order_data['created_at']
            ))
            
            self.conn.commit()
            self.logger.info(f"ì‘ì—…ìš”ì²­ ì €ì¥ ì™„ë£Œ: ITEMNO={work_order_data['itemno']}")
            return True
            
        except Exception as e:
            self.logger.error(f"ì‘ì—…ìš”ì²­ ì €ì¥ ì˜¤ë¥˜: {e}")
            return False
    
    def close(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ"""
        if self.conn:
            self.conn.close()

# ì „ì—­ ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
db_manager = DatabaseManager() 